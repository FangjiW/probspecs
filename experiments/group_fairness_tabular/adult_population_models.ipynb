{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "\n",
    "from fairnessdatasets import Adult\n",
    "import dill\n",
    "from kmodes.kmodes import KModes\n",
    "from scipy.stats import truncnorm, beta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from probspecs import *\n",
    "from probspecs.distributions import *\n",
    "\n",
    "from input_spaces import adult_input_space\n",
    "\n",
    "torch.manual_seed(353710130163567)\n",
    "np.random.seed(2548400)\n",
    "random.seed(635404273475618)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset is with one-hot encodings and normalisation,\n",
    "# dataset_raw is without.\n",
    "dataset = Adult(root=\"../../.datasets\", download=True)\n",
    "test_set = Adult(root=\"../../.datasets\", train=False, download=True)\n",
    "dataset_raw = Adult(root=\"../../.datasets\", raw=True, download=True)\n",
    "test_data_raw = Adult(root=\"../../.datasets\", train=False, raw=True, download=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7432bc8d28080e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# We use data_df for plotting\n",
    "data_df = pd.DataFrame(dataset_raw.data, columns=dataset_raw.columns)\n",
    "# Convert categorical variables from integer ids to string names\n",
    "for var, values in Adult.variables.items():\n",
    "    if values is not None:\n",
    "        data_df[f\"{var}-names\"] = data_df[var]\n",
    "        for i, value in enumerate(values):\n",
    "            data_df[f\"{var}-names\"].replace(i, value, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cca949b56b07e40a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Changes in capital are split in the dataset across the variables \"capital-gain\" and \"capital-loss\".\n",
    "Here, capital-loss is zero whenever capital-gain is greater zero and the other way around.\n",
    "We summarize the two values in a single additional variable \"capital-change\".\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d686b8a46554adb0"
  },
  {
   "cell_type": "code",
   "source": [
    "data_df[\"capital-change\"] = data_df[\"capital-gain\"] - data_df[\"capital-loss\"]\n",
    "# Used later to differentiate original training data and generated data\n",
    "data_df[\"dataset\"] = \"train\"\n",
    "data_df\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "824c93c221796c82",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some utilities for working with the data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ff8ef91c310d48d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Map column names to column indices (especially relevant for one-hot encoded attributes)\n",
    "col_idx = {\n",
    "    var: [\n",
    "        i\n",
    "        for i, col in enumerate(dataset.columns)\n",
    "        if col == var or col.startswith(f\"{var}=\")\n",
    "    ]\n",
    "    for var in adult_input_space.attribute_names\n",
    "}\n",
    "col_idx[\"capital-change\"] = [-1]\n",
    "col_raw_id = {  # for accessing non-one-hot-encoded categorical variables\n",
    "    var: dataset_raw.columns.index(var) for var in adult_input_space.attribute_names\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c5fab47b1db3990",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def entropy(frequencies):\n",
    "    p = frequencies\n",
    "    # avoid computing log of 0.0, instead replace by log(1.0) = 0.0\n",
    "    return -np.sum(p * np.log(p))\n",
    "\n",
    "def conditional_entropy(joint_frequencies, conditioned_on):\n",
    "    # compute H(X|Y)\n",
    "    p_xy = joint_frequencies\n",
    "    p_y = p_xy.groupby(conditioned_on).sum()\n",
    "    return -np.sum(p_xy * np.log(p_xy / p_y))\n",
    "\n",
    "def uncertainty_coefficient(source_vars, target_var):\n",
    "    \"\"\"\n",
    "    Measures association between variables. \n",
    "     - 0.0 => no association.\n",
    "     - 1.0 => sources can predict target perfectly.\n",
    "    \"\"\"\n",
    "    target_frequencies = data_df.value_counts(subset=[target_var], normalize=True)\n",
    "    joint_frequencies = data_df.value_counts(subset=source_vars + [target_var], normalize=True)\n",
    "    h_x = entropy(target_frequencies)\n",
    "    h_x_given_y = conditional_entropy(joint_frequencies, source_vars)\n",
    "    uncertainty_coef = (h_x - h_x_given_y) / h_x\n",
    "\n",
    "    print(f\"U({target_var}|{source_vars}) = {uncertainty_coef:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "806050069283aa7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Marginal Distributions\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6477eaf9a33f205e"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplot_mosaic(\n",
    "    [\n",
    "        [\"age\", \"workclass\", \"fnlwgt\", \"education\"],\n",
    "        [\"education-num\", \"marital-status\", \"occupation\", \"relationship\"],\n",
    "        [\"race\", \"sex\", \"native-country\", \"native-country\"],\n",
    "        [\"hours-per-week\"] * 4,\n",
    "        [\"capital-gain-full\"] * 2 + [\"capital-gain-non-zero\"] * 2,\n",
    "        [\"capital-loss-full\"] * 2 + [\"capital-loss-non-zero\"] * 2,\n",
    "    ],\n",
    "    figsize=(15, 30)\n",
    ")\n",
    "for var in adult_input_space.attribute_names:\n",
    "    if var in (\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"native-country\",\n",
    "    ): # categorical variables\n",
    "        var_show = var\n",
    "        if var != \"education-num\":\n",
    "            var_show = f\"{var}-names\"\n",
    "        g = sns.histplot(\n",
    "            data_df,\n",
    "            x=var_show,\n",
    "            discrete=True,\n",
    "            shrink=0.8,\n",
    "            multiple=\"dodge\",\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            legend=False,\n",
    "            ax=axes[var],\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "        axes[var].tick_params(axis='x', labelrotation=90)\n",
    "    elif var.startswith(\"capital\"):\n",
    "        for exclude_zero in (True, False):\n",
    "            if exclude_zero:\n",
    "                df = data_df[data_df[\"capital-change\"] != 0]\n",
    "                ax_key = f\"{var}-non-zero\"\n",
    "            else:\n",
    "                df = data_df\n",
    "                ax_key = f\"{var}-full\"\n",
    "            g = sns.histplot(\n",
    "                df,\n",
    "                x=var,\n",
    "                common_norm=False,\n",
    "                stat=\"density\",\n",
    "                kde=True,\n",
    "                bins=150,\n",
    "                ax=axes[ax_key],\n",
    "            )\n",
    "            if not exclude_zero:\n",
    "                g.set(title=f\"{var} - All Data\")\n",
    "            else:\n",
    "                g.set(title=f\"{var} - Without Zero\")\n",
    "            g.set(xlabel=None)\n",
    "    else:\n",
    "        kwargs = {\"legend\": False}\n",
    "        if var in (\"age\", \"hours-per-week\"):\n",
    "            kwargs[\"binwidth\"] = 1.0\n",
    "            kwargs[\"legend\"] = True\n",
    "        if var == (\"hours-per-week\"):\n",
    "            kwargs[\"multiple\"] = \"dodge\"\n",
    "        if var in (\"age\", \"fnlwgt\"):\n",
    "            kwargs[\"kde\"] = True\n",
    "        g = sns.histplot(\n",
    "            data_df,\n",
    "            x=var,\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            ax=axes[var],\n",
    "            **kwargs,\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "plt.subplots_adjust(hspace=1.0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "193d42f64435fd98",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation Heatmap\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "805bfc354a108732"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.heatmap(\n",
    "    torch.corrcoef(dataset_raw.data.T),\n",
    "    vmin=-1.0,\n",
    "    vmax=1.0,\n",
    "    square=True,\n",
    "    cmap=\"RdBu\",\n",
    "    xticklabels=dataset_raw.columns,\n",
    "    yticklabels=dataset_raw.columns,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb34b2a9cd4666f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Duplicated Information\n",
    "Some variables encode the same information, such as `sex` and `relationship`\n",
    "with the values `Husband` and `Wife`.\n",
    "We first have a closer look now at the relationships between the categorical variables.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8295dbb9e3827cda"
  },
  {
   "cell_type": "code",
   "source": [
    "uncertainty_coefficient(source_vars=[\"education\"], target_var=\"education-num\")\n",
    "uncertainty_coefficient(source_vars=[\"occupation\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"workclass\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"relationship\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"marital-status\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"relationship\", \"sex\"], target_var=\"marital-status\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "309dda8c8faec5e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see from the above, `education-num` is a complete duplicate of `education`.\n",
    "There is also substantial overlap between `relationship` and `marital-status`.\n",
    "Let's have a closer look."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bfc1e15c61a8e8e"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "g = sns.pairplot(\n",
    "    data_df,\n",
    "    vars=(\"sex-names\", \"relationship-names\", \"marital-status-names\"),\n",
    "    kind=\"hist\",\n",
    "    plot_kws={\"discrete\": True, \"stat\": \"frequency\"},\n",
    ")\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "681cef7ef3d24f5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "g = sns.histplot(data_df, y=\"occupation-names\", x=\"workclass-names\", discrete=True, stat=\"frequency\")\n",
    "g.axes.tick_params(axis=\"x\", labelrotation=90)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "775ce79e7794c50a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The blank fields in the above plots show that some information is duplicated\n",
    "in the variables.\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bea00cc531894b08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Population Models\n",
    "We are now ready to build our population models.\n",
    "\n",
    "## General Utilities\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "370086ab5557415b"
  },
  {
   "cell_type": "code",
   "source": [
    "def get_seed(string):\n",
    "    as_bytes = bytes(string[:3] + string[-3:], \"utf-8\")\n",
    "    return int.from_bytes(as_bytes, \"big\")\n",
    "\n",
    "def _get_mean_std_min_max(data_, var=None, var_min=None, var_max=None):\n",
    "    if var_min is not None:\n",
    "        min_, max_ = var_min, var_max\n",
    "    elif var is not None:\n",
    "        min_, max_ = adult_input_space.attribute_bounds(var)\n",
    "    else:\n",
    "        raise ValueError(\"var and var_min/var_max may not both be None.\")\n",
    "    mean_ = data_.mean().item()\n",
    "    std_ = data_.std().item()\n",
    "    return mean_, std_, min_, max_\n",
    "\n",
    "\n",
    "def make_truncnorm(data_, var=None, var_min=None, var_max=None):\n",
    "    mean_, std_, min_, max_ = _get_mean_std_min_max(data_, var, var_min, var_max)\n",
    "    # truncnorm needs min_ and max_ to be the number of standard deviations from loc\n",
    "    min_ = (min_ - mean_) / std_\n",
    "    max_ = (max_ - mean_) / std_\n",
    "    distribution = truncnorm(a=min_, b=max_, loc=mean_, scale=std_)\n",
    "    return AsInteger.wrap(distribution)\n",
    "\n",
    "\n",
    "def make_gaussian_mixture(data_, n_components, n_restarts=1, var=None, var_min=None, var_max=None):\n",
    "    if var is not None:\n",
    "        bounds = adult_input_space.attribute_bounds(var)\n",
    "    else:\n",
    "        bounds = (var_min, var_max)\n",
    "    seed = get_seed(f\"mix-{var}\")\n",
    "    mixture = MixtureModel.fit_truncnorm_mixture(data_, bounds, n_components, n_restarts, seed=seed)\n",
    "    return AsInteger(mixture)\n",
    "\n",
    "\n",
    "def make_categorical(data_one_hot_):\n",
    "    \"\"\"Creates a one-hot categorical distribution\"\"\"\n",
    "    class_frequencies = data_one_hot_.mean(dim=0)\n",
    "    return CategoricalOneHot(class_frequencies)\n",
    "\n",
    "\n",
    "def make_categorical_flat(data_, num_values):\n",
    "    \"\"\"\n",
    "    Makes a \"flat\" categorical distribution, \n",
    "    producing values from 0 to n-1 (for n categories)\n",
    "    \"\"\"\n",
    "    data_one_hot_ = torch.eye(num_values)[data_.long()]\n",
    "    class_frequencies = data_one_hot_.mean(dim=0)\n",
    "    class_frequencies = torch.clamp(class_frequencies, min=0.0, max=1.0)\n",
    "    return Categorical(class_frequencies)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c026448db725e4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Independent Population Model\n",
    "Only model the variables separately, disregarding interactions between\n",
    "variables. \n",
    "Note that under this assumption, a classifier can achieve fairness simply\n",
    "by disregarding the sensitive attribute.\n",
    "Therefore, the independent population model is only for testing purposes.\n",
    "\n",
    "## Distributions\n",
    "We fit Multinouli distributions to all categorical variables.\n",
    "\n",
    "### Categorical Variables\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ac60670879e78a"
  },
  {
   "cell_type": "code",
   "source": [
    "distributions = {\n",
    "    \"workclass\": make_categorical(dataset.data[:, col_idx[\"workclass\"]]),\n",
    "    \"education\": make_categorical(dataset.data[:, col_idx[\"education\"]]),\n",
    "    \"marital-status\": make_categorical(dataset.data[:, col_idx[\"marital-status\"]]),\n",
    "    \"occupation\": make_categorical(dataset.data[:, col_idx[\"occupation\"]]),\n",
    "    \"relationship\": make_categorical(dataset.data[:, col_idx[\"relationship\"]]),\n",
    "    \"race\": make_categorical(dataset.data[:, col_idx[\"race\"]]),\n",
    "    \"sex\": make_categorical(dataset.data[:, col_idx[\"sex\"]]),\n",
    "    \"native-country\": make_categorical(dataset.data[:, col_idx[\"native-country\"]]),\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c44ba5331e431291",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "n = 10000\n",
    "generated_raw = {}\n",
    "for var in distributions:\n",
    "    # we have to use different seeds per variable, otherwise we would get\n",
    "    # highly correlated samples\n",
    "    values_one_hot = distributions[var].sample(n, seed=get_seed(var))\n",
    "    values = np.argmax(values_one_hot, axis=1)\n",
    "    generated_raw[var] = values\n",
    "\n",
    "generated_df = pd.DataFrame(generated_raw)\n",
    "generated_df[\"dataset\"] = \"generated\"\n",
    "df = pd.concat([generated_df, data_df])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c068bb28d492d51",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 7.5))\n",
    "axes = axes.flatten()\n",
    "for var, ax in zip(distributions.keys(), axes):\n",
    "    ax.set_title(var)\n",
    "    g = sns.histplot(\n",
    "        df,\n",
    "        x=var,\n",
    "        hue=\"dataset\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"percent\",\n",
    "        common_norm=False,\n",
    "        ax=ax,\n",
    "        legend=var == \"native-country\",\n",
    "    )\n",
    "    g.set(xlabel=None)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92d615286eed8e87",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Continuous Variables\n",
    "\n",
    "For the continuous variables, we use\n",
    "- age: truncated Normal distribution\n",
    "- fnlwght: Beta distribution\n",
    "- education-num: Categorical distribution (as there are few values)\n",
    "- hours-per-week: Categorical distribution (as the distribution is pretty spiky)\n",
    "- capital-gain: Gaussian Mixture Model\n",
    "- capital-loss: Gaussian Mixture Model\n",
    "\n",
    "All \"continuous\" variables in the Adult dataset are actually integer variables.\n",
    "Therefore, we wrap all distributions as a `AsInteger`.\n",
    "\n",
    "#### Age\n",
    "The histogram of `age` looks a lot like a normal distribution.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4a915a54ab67ab8"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df, x=\"age\", stat=\"percent\", kde=True, binwidth=1.0,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9e7f9155bed467d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "age_min, age_max = adult_input_space.attribute_bounds(\"age\")\n",
    "\n",
    "age_loc = 33.0\n",
    "age_scale = 17.0\n",
    "distributions[\"age\"] = AsInteger.wrap(truncnorm(\n",
    "    a=(age_min - age_loc) / age_scale,\n",
    "    b=(age_max - age_loc) / age_scale,\n",
    "    loc=age_loc,\n",
    "    scale=age_scale,\n",
    "))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c3feb6929071ab3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "age_data = distributions[\"age\"].sample(n, seed=get_seed(\"age\"))\n",
    "\n",
    "generated_df[\"age\"] = age_data\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_ = sns.histplot(\n",
    "    df, x=\"age\", hue=\"dataset\", stat=\"density\", common_norm=False, kde=True, binwidth=1.0\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63daba9c4b5ae208",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### fnlwgt\n",
    "`fnlwgt` is an estimate of a proportion, so we model it using a Beta distribution.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b383383ba189f6b"
  },
  {
   "cell_type": "code",
   "source": [
    "# The beta distribution produces values between 0.0 and 1.0. \n",
    "# Therefore, we want to move 0.0 to fnlwgt_min and 1.0 to fnlwgt_max\n",
    "fnlwgt_min, fnlwgt_max = adult_input_space.attribute_bounds(\"fnlwgt\")\n",
    "fnlwgt_data = dataset_raw.data[:, col_raw_id[\"fnlwgt\"]]\n",
    "distributions[\"fnlwgt\"] = AsInteger.wrap(UnivariateContinuousDistribution(\n",
    "    beta(\n",
    "        a=4.25,\n",
    "        b=30.0,\n",
    "        loc=fnlwgt_min,  \n",
    "        scale=fnlwgt_max,\n",
    "    ), \n",
    "    bounds=(fnlwgt_min, fnlwgt_max)\n",
    "))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d127728df4b2fa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fnlwgt_data = distributions[\"fnlwgt\"].sample(n, seed=get_seed(\"fnlwgt\"))\n",
    "\n",
    "generated_df[\"fnlwgt\"] = fnlwgt_data\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_ = sns.histplot(\n",
    "    df, x=\"fnlwgt\", hue=\"dataset\", stat=\"density\", common_norm=False, kde=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c55584391d509e4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### education-num\n",
    "Education num has few discrete values, so we model it using a categorical\n",
    "distribution.\n",
    "The one-hot values of the categorical distribution are converted to \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2657f0d12bcd1b6c"
  },
  {
   "cell_type": "code",
   "source": [
    "edu_num_data = dataset_raw.data[:, col_raw_id[\"education-num\"]]\n",
    "edu_num_num_values = edu_num_data.max() + 1\n",
    "distributions[\"education-num\"] = make_categorical_flat(edu_num_data, int(edu_num_num_values))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1e01768a3eedbd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "edu_num_data = distributions[\"education-num\"].sample(n, seed=get_seed(\"education-num\"))\n",
    "generated_df[\"education-num\"] = edu_num_data\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_ = sns.histplot(\n",
    "    df,\n",
    "    x=\"education-num\",\n",
    "    hue=\"dataset\",\n",
    "    discrete=True,\n",
    "    shrink=0.8,\n",
    "    multiple=\"dodge\",\n",
    "    stat=\"percent\",\n",
    "    common_norm=False,\n",
    "    legend=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15272dfd0f3eead8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### hours-per-week\n",
    "When we look at `hours-per-week`, we see a scattered distribution.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b18cd80e186f2cb"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df, x=\"hours-per-week\", stat=\"percent\", binwidth=1.0,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3ea5fc1fc21767b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "work_hours_data = dataset_raw.data[:, col_raw_id[\"hours-per-week\"]]\n",
    "work_hours_data = work_hours_data.reshape(-1, 1)\n",
    "distributions[\"hours-per-week\"] = make_categorical_flat(work_hours_data, 100)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edba139a48632874",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "work_hours_data = distributions[\"hours-per-week\"].sample(n, seed=get_seed(\"hours-per-week\"))\n",
    "\n",
    "generated_df[\"hours-per-week\"] = work_hours_data.reshape(-1)\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    df,\n",
    "    x=\"hours-per-week\",\n",
    "    hue=\"dataset\",\n",
    "    multiple=\"dodge\",\n",
    "    stat=\"percent\",\n",
    "    common_norm=False,\n",
    "    binwidth=1.0,\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2736c43a8d717bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### capital-gain\n",
    "The empirical distribution of `capital-gain` is complex.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86df3b9ab11db0e9"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_, axes = plt.subplots(1, 2, figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"capital-gain\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    ax=axes[0]\n",
    ")\n",
    "_ = sns.histplot(\n",
    "    data_df[data_df[\"capital-gain\"] > 0],\n",
    "    x=\"capital-gain\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    ax=axes[1]\n",
    ")\n",
    "_ = axes[0].set_title(\"All Data\")\n",
    "_ = axes[1].set_title(\"Excluding Zero\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62260627ba739008",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We model the outliers `0` (this stems from the complementarity of \n",
    "`capital-gain` and `capital-loss`) and `100000` using a Categorical distribution.\n",
    "For the remainder of the data, we fit a Gaussian mixture model.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b2902c64a1005eb"
  },
  {
   "cell_type": "code",
   "source": [
    "capital_gain_data = data_df[\"capital-gain\"]\n",
    "outliers = [0, capital_gain_data.max()]\n",
    "outlier_data = capital_gain_data[capital_gain_data.isin(outliers)]\n",
    "regular_data = capital_gain_data[~capital_gain_data.isin(outliers)]\n",
    "\n",
    "outlier_count = outlier_data.astype(int).value_counts(normalize=True)\n",
    "outliers_distribution = Categorical(\n",
    "    [outlier_count[o] for o in outliers], outliers\n",
    ")\n",
    "\n",
    "regular_data = regular_data.to_numpy().reshape(-1, 1)\n",
    "mixture_model = make_gaussian_mixture(regular_data, var=\"capital-gain\", n_components=3, n_restarts=3)\n",
    "mixture_model = mixture_model.continuous_distribution\n",
    "\n",
    "# add the outlier distribution to the mixture model\n",
    "components = list(mixture_model.distributions) + [outliers_distribution]\n",
    "weights = list(mixture_model.weights * len(regular_data)/len(data_df))\n",
    "weights += [len(outlier_data)/len(data_df)]\n",
    "distributions[\"capital-gain\"] = AsInteger(MixtureModel(weights, components))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f1f70dfa4fe81a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "capital_gain_data = distributions[\"capital-gain\"].sample(n, seed=get_seed(\"capital-gain\"))\n",
    "\n",
    "generated_df[\"capital-gain\"] = capital_gain_data.reshape(-1)\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    df,\n",
    "    x=\"capital-gain\",\n",
    "    hue=\"dataset\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    common_norm=False,\n",
    "    ax=axes[0]\n",
    ")\n",
    "_ = sns.histplot(\n",
    "    df[df[\"capital-gain\"] > 0],\n",
    "    x=\"capital-gain\",\n",
    "    hue=\"dataset\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    common_norm=False,\n",
    "    ax=axes[1]\n",
    ")\n",
    "_ = axes[0].set_title(\"All Data\")\n",
    "_ = axes[1].set_title(\"Excluding Zero\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43c6e7b2d0d54185",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### capital-loss\n",
    "The `capital-loss` feature is a little less complex than the `capital-gain`\n",
    "feature, but has some of the same issues.\n",
    "Notably, it also has an outlier at `0` for the same reasons as `capital-gain` has one.\n",
    "\n",
    "We model `capital-loss` the same way as we model `capital-gain`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf81c0df57fcb922"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_, axes = plt.subplots(1, 2, figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"capital-loss\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    ax=axes[0]\n",
    ")\n",
    "_ = sns.histplot(\n",
    "    data_df[data_df[\"capital-loss\"] > 0],\n",
    "    x=\"capital-loss\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    ax=axes[1]\n",
    ")\n",
    "_ = axes[0].set_title(\"All Data\")\n",
    "_ = axes[1].set_title(\"Excluding Zero\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ff247b391799e8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "capital_loss_data = data_df[\"capital-loss\"]\n",
    "outlier_data = capital_loss_data[capital_loss_data == 0.0]\n",
    "regular_data = capital_loss_data[capital_loss_data > 0.0]\n",
    "\n",
    "outliers_distribution = Categorical([1.0], [0.0])\n",
    "\n",
    "regular_data = regular_data.to_numpy().reshape(-1, 1)\n",
    "mixture_model = make_gaussian_mixture(regular_data, var=\"capital-loss\", n_components=8, n_restarts=3)\n",
    "mixture_model = mixture_model.continuous_distribution\n",
    "\n",
    "# add the outlier distribution to the mixture model\n",
    "components = list(mixture_model.distributions) + [outliers_distribution]\n",
    "weights = list(mixture_model.weights * len(regular_data)/len(data_df))\n",
    "weights += [len(outlier_data)/len(data_df)]\n",
    "distributions[\"capital-loss\"] = AsInteger(MixtureModel(weights, components))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f48ed08d3d8b83a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "capital_loss_data = distributions[\"capital-loss\"].sample(n, seed=get_seed(\"capital-loss\"))\n",
    "\n",
    "generated_df[\"capital-loss\"] = capital_loss_data.reshape(-1)\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    df,\n",
    "    x=\"capital-loss\",\n",
    "    hue=\"dataset\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    common_norm=False,\n",
    "    ax=axes[0]\n",
    ")\n",
    "_ = sns.histplot(\n",
    "    df[df[\"capital-loss\"] > 0],\n",
    "    x=\"capital-loss\",\n",
    "    hue=\"dataset\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    common_norm=False,\n",
    "    ax=axes[1]\n",
    ")\n",
    "_ = axes[0].set_title(\"All Data\")\n",
    "_ = axes[1].set_title(\"Excluding Zero\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cad6438493d7dfa3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare Correlation Matrices\n",
    "Just to remind ourselves that this is the *independent* population model,\n",
    "that is, all the variables are independent.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c77997654dbd20a"
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "axes[0].set_title(\"Population Model\")\n",
    "generated_df_ = generated_df.drop(\"dataset\", axis=1)\n",
    "_ = sns.heatmap(\n",
    "    np.corrcoef(generated_df_.to_numpy().T),\n",
    "    vmin=-1.0,\n",
    "    vmax=1.0,\n",
    "    square=True,\n",
    "    cmap=\"RdBu\",\n",
    "    xticklabels=dataset_raw.columns,\n",
    "    yticklabels=dataset_raw.columns,\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[1].set_title(\"Training Data\")\n",
    "_ = sns.heatmap(\n",
    "    torch.corrcoef(dataset_raw.data.T),\n",
    "    vmin=-1.0,\n",
    "    vmax=1.0,\n",
    "    square=True,\n",
    "    cmap=\"RdBu\",\n",
    "    xticklabels=dataset_raw.columns,\n",
    "    yticklabels=dataset_raw.columns,\n",
    "    ax=axes[1],\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a047a00aa95969b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export Population Model\n",
    "\n",
    "We need to export the probability distribution and a description of the space \n",
    "of values that are produced by the probability distribution.\n",
    "Additionally, the values of the continuous attributes need to be normalized before \n",
    "being fed to a classifier.\n",
    "We perform normalization sing a linear neural network layer.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e153f9301835125"
  },
  {
   "cell_type": "code",
   "source": [
    "# Input Space\n",
    "ind_input_space = adult_input_space\n",
    "\n",
    "# Distribution\n",
    "ind_distribution = MultivariateIndependent(\n",
    "    *[distributions[var] for var in ind_input_space.attribute_names], \n",
    "    event_shape=ind_input_space.input_shape,\n",
    ")\n",
    "\n",
    "# Transformation (z-Score Normalization)\n",
    "mean = dataset_raw.data.mean(dim=0)\n",
    "std = dataset_raw.data.std(dim=0)\n",
    "# we want to calculate: (x - mean) / std = x/std - mean/std\n",
    "weight = torch.zeros(adult_input_space.input_shape + ind_input_space.input_shape)\n",
    "bias = torch.zeros(adult_input_space.input_shape)\n",
    "w_i = w_j = 0\n",
    "for i, var in enumerate(ind_input_space.attribute_names):\n",
    "    match ind_input_space.attribute_type(var):\n",
    "        case TabularInputSpace.AttributeType.CATEGORICAL:\n",
    "            for _ in range(len(ind_input_space.attribute_values(var))):\n",
    "                weight[w_i, w_j] = 1.0\n",
    "                w_i += 1\n",
    "                w_j += 1\n",
    "        case _:\n",
    "            weight[w_i, w_j] = 1/std[i]\n",
    "            bias[w_i] = mean[i]/std[i]\n",
    "            w_i += 1\n",
    "            w_j += 1\n",
    "ind_transform = nn.Linear(weight.size(1), weight.size(0), bias=True)\n",
    "with torch.no_grad():\n",
    "    ind_transform.weight = nn.Parameter(weight, requires_grad=False)\n",
    "    ind_transform.bias = nn.Parameter(bias, requires_grad=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5da60b3cfa4ef027",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(\n",
    "    (ind_distribution, ind_input_space, ind_transform),\n",
    "    \"../../resources/adult/independent_population_model.pyt\",\n",
    "    pickle_module=dill,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fd724f7f1fa64da",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bayesian Network Population Model\n",
    "\n",
    "For this population model, we manually create a network layout of a Bayesian network\n",
    "and then manually devise the conditional distributions for the variables\n",
    "in the graph.\n",
    "\n",
    "We will use `native-country` as a root variable, but group the values by \n",
    "larger regions.\n",
    "Our goal is that every region contains more than 1% of the samples in the dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2889d151f6c7469"
  },
  {
   "cell_type": "code",
   "source": [
    "country_to_region = {\n",
    "    \"United-States\": \"North-America\",\n",
    "    \"Canada\": \"North-America\",\n",
    "    \"Mexico\": \"Mexico\",  # Give Mexico an own region because of the relatively high number of Mexicans in dataset\n",
    "    \"Puerto-Rico\": \"South&Central-America&Pacific\",\n",
    "    \"Cuba\": \"South&Central-America&Pacific\",\n",
    "    \"Jamaica\": \"South&Central-America&Pacific\",\n",
    "    \"Haiti\": \"South&Central-America&Pacific\",\n",
    "    \"Trinadad&Tobago\": \"South&Central-America&Pacific\",\n",
    "    \"Guatemala\": \"South&Central-America&Pacific\",\n",
    "    \"Honduras\": \"South&Central-America&Pacific\",\n",
    "    \"Nicaragua\": \"South&Central-America&Pacific\",\n",
    "    \"El-Salvador\": \"South&Central-America&Pacific\",\n",
    "    \"Dominican-Republic\": \"South&Central-America&Pacific\",\n",
    "    \"Ecuador\": \"South&Central-America&Pacific\",\n",
    "    \"Peru\": \"South&Central-America&Pacific\",\n",
    "    \"Columbia\": \"South&Central-America&Pacific\",\n",
    "    \"Outlying-US(Guam-USVI-etc)\": \"South&Central-America&Pacific\",\n",
    "    \"Cambodia\": \"Asia\",\n",
    "    \"Japan\": \"Asia\",\n",
    "    \"China\": \"Asia\",\n",
    "    \"Vietnam\": \"Asia\",\n",
    "    \"Taiwan\": \"Asia\",\n",
    "    \"Thailand\": \"Asia\",\n",
    "    \"Philippines\": \"Asia\",\n",
    "    \"Laos\": \"Asia\",\n",
    "    \"Iran\": \"Asia\",\n",
    "    \"India\": \"Asia\",\n",
    "    \"Hong\": \"Asia\",  # Assuming Hong = Hong Kong\n",
    "    \"South\": \"Asia\",  # Assuming South = South Korea and not South Africa, as there are no African countries present otherwise.\n",
    "    \"England\": \"Europe\",\n",
    "    \"Germany\": \"Europe\",\n",
    "    \"Greece\": \"Europe\",\n",
    "    \"Italy\": \"Europe\",\n",
    "    \"Poland\": \"Europe\",\n",
    "    \"Portugal\": \"Europe\",\n",
    "    \"Ireland\": \"Europe\",\n",
    "    \"France\": \"Europe\",\n",
    "    \"Hungary\": \"Europe\",\n",
    "    \"Scotland\": \"Europe\",\n",
    "    \"Yugoslavia\": \"Europe\",\n",
    "    \"Holand-Netherlands\": \"Europe\",\n",
    "}\n",
    "# order country_to_region by order of countries in dataset\n",
    "country_to_region = dict([\n",
    "    (country, country_to_region[country])\n",
    "    for country in Adult.variables[\"native-country\"]\n",
    "])\n",
    "\n",
    "data_df[\"native-region-names\"] = data_df[\"native-country\"]\n",
    "country_to_index = dict([(var, float(i)) for i, var in enumerate(Adult.variables[\"native-country\"])])\n",
    "for country, region in country_to_region.items():\n",
    "    data_df[\"native-region-names\"].replace(country_to_index[country], region, inplace=True)\n",
    "\n",
    "data_df[\"native-region\"] = data_df[\"native-region-names\"]\n",
    "for i, region in enumerate(country_to_region.values()):\n",
    "    data_df[\"native-region\"].replace(region, i, inplace=True)\n",
    "data_df[\"native-region\"] = data_df[\"native-region\"].astype(float)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1f0bbad226edeb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "native_regions = pd.unique(data_df[\"native-region-names\"])\n",
    "overview = pd.DataFrame()\n",
    "overview[\"count\"] = data_df[\"native-region-names\"].value_counts()\n",
    "overview[\"proportion\"] = data_df[\"native-region-names\"].value_counts(normalize=True)\n",
    "overview\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaf18c5d21e0b4d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the Network\n",
    "### native-country\n",
    "We posit `native-country` as the only root variable of our Bayesian network.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d2b9dfc6bd81f15"
  },
  {
   "cell_type": "code",
   "source": [
    "bayes_net_factory = BayesianNetwork.Factory()\n",
    "native_country_node = bayes_net_factory.new_node(\"native-country\", replace=True)\n",
    "num_countries = len(Adult.variables[\"native-country\"])\n",
    "native_country_node.one_hot_event_space(num_countries)\n",
    "native_country_node.set_conditional_probability({}, make_categorical(dataset.data[:, col_idx[\"native-country\"]]))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6be6992de83c73ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# lower and upper bounds for checking if a \"native-country\" value is in a certain \"native-region\"\n",
    "native_region_mask = {\n",
    "    region: (\n",
    "        torch.zeros(num_countries),\n",
    "        torch.tensor([1.0 if region == region_ else 0.0 for region_ in country_to_region.values()])\n",
    "    )\n",
    "    for region in native_regions\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f15e7c8d9cc6f9ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sex\n",
    "The correlation plot exhibits little correlation between `sex` and `native-country`.\n",
    "However, since `native-country` is heavily dominated by the US, this is not very\n",
    "informative.\n",
    "In fact, on a closer look, we observe significant imbalances in `sex` relative to\n",
    "the `native-region`.\n",
    "\n",
    "While this maybe counterintuitive, these differences can be explained, \n",
    "for example, due to gender imbalances among the people immigrating to the US.\n",
    "In this case, `native-country` and `sex` would actually be independent, but a hidden\n",
    "factor `immigrate` that determines inclusion in this dataset confounds the two variables.\n",
    "\n",
    "However, due to practices like female infanticide or gender-selective abortion,\n",
    "`native-country` and `sex` may indeed not be independent.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5fdd3ceef70dec2"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, ax = plt.subplots(figsize=(10.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"sex-names\",\n",
    "    hue=\"native-region-names\",\n",
    "    multiple=\"dodge\",\n",
    "    shrink=0.8,\n",
    "    stat=\"percent\",\n",
    "    common_norm=False,\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aa352503814d6d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sex_node = bayes_net_factory.new_node(\"sex\", replace=True)  # if running this cell multiple times\n",
    "sex_node.set_parents(native_country_node)\n",
    "sex_node.one_hot_event_space(len(Adult.variables[\"sex\"]))\n",
    "\n",
    "for i, region_value in enumerate(native_regions):\n",
    "    region_mask = native_region_mask[region_value]\n",
    "    country_matches = torch.all(dataset.data[:, col_idx[\"native-country\"]] <= region_mask[1], dim=-1)\n",
    "    sex_values = dataset.data[country_matches, :][:, col_idx[\"sex\"]]\n",
    "    sex_node.set_conditional_probability(\n",
    "        {native_country_node: region_mask},\n",
    "        make_categorical(sex_values)\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aff4fac26b52f91f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Race\n",
    "Next, we model `race` depending on `sex` and `native-country` (grouped by region).\n",
    "Although making `race` dependent on `sex` seems non-sensical, \n",
    "we observe differences in the distribution of `race` dependent on `sex`.\n",
    "These differences may be related to the mechanism that leads to the overall\n",
    "imbalance in `sex` in the dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ce271ed33770b00"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i, var in enumerate((\"sex-names\", \"native-region-names\")):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=var,\n",
    "        hue=\"race-names\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"percent\",\n",
    "        common_norm=False,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    g.set(title=\"Bars in Each Color Sum to 100%\")\n",
    "    axes[i].tick_params(axis='x', labelrotation=90, labelbottom=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8755b77cb607a542",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "race_node = bayes_net_factory.new_node(\"race\", replace=True)\n",
    "race_node.set_parents(sex_node, native_country_node)\n",
    "race_node.one_hot_event_space(len(Adult.variables[\"race\"]))\n",
    "\n",
    "for i, _ in enumerate(Adult.variables[\"sex\"]):\n",
    "    for j, region_value in enumerate(native_regions):\n",
    "        sex_matches = dataset.data[:, col_idx[\"sex\"][i]] == 1.0\n",
    "        region_mask = native_region_mask[region_value]\n",
    "        country_matches = torch.all(dataset.data[:, col_idx[\"native-country\"]] <= region_mask[1], dim=-1)\n",
    "        race_values = dataset.data[sex_matches & country_matches, :][:, col_idx[\"race\"]]\n",
    "        race_node.set_conditional_probability(\n",
    "            {sex_node: torch.eye(2)[i, :], native_country_node: region_mask},\n",
    "            make_categorical(race_values)\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d79646cf5f58dec",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With three variables, some subpopulations that match on all three are as small\n",
    "as a single individual.\n",
    "In fact, this already holds true for the combination of `native-country` and `race`.\n",
    "\n",
    "We now look at the size of these subpopulations and summarize those populations\n",
    "for which we have little data. \n",
    "The following variables then depend on `native-country`, `sex` and `race`\n",
    "only for these summarized subpopulations.\n",
    "The goal is that the subpopulations include at least (about) 500 individuals.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "644698ec35ca4157"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(1, len(native_regions), figsize=(15, 3))\n",
    "\n",
    "for j, region_value in enumerate(native_regions):\n",
    "    subset_df = data_df.loc[(data_df[\"native-region-names\"] == region_value)]\n",
    "    subset_df = subset_df.sort_values(by=[\"race\", \"sex\"])\n",
    "    g = sns.histplot(\n",
    "        subset_df,\n",
    "        x=\"race-names\",\n",
    "        hue=\"sex-names\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"count\",\n",
    "        ax=axes[j],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[j].tick_params(axis='x', labelrotation=90, labelbottom=True)\n",
    "\n",
    "for j, region_value in enumerate(native_regions):\n",
    "    axes[j].set_title(region_value)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da53f045484ced88",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "subset_df = data_df.loc[(data_df[\"native-region-names\"] == \"North-America\")]\n",
    "subset_df = subset_df.sort_values(by=[\"race\", \"sex\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "g = sns.histplot(\n",
    "    subset_df,\n",
    "    x=\"race-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True,\n",
    "    shrink=0.8,\n",
    "    multiple=\"dodge\",\n",
    "    log_scale=(False, True),\n",
    "    ax=axes[0],\n",
    ")\n",
    "g.set(xlabel=None)\n",
    "axes[0].tick_params(axis='x', labelrotation=90, labelbottom=True)\n",
    "_ = axes[0].set_title(\"North-America Logarithmic\")\n",
    "\n",
    "g = sns.histplot(\n",
    "    subset_df,\n",
    "    x=\"race-names\",\n",
    "    hue=\"sex-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True,\n",
    "    shrink=0.8,\n",
    "    multiple=\"dodge\",\n",
    "    log_scale=(False, True),\n",
    "    ax=axes[1],\n",
    ")\n",
    "g.set(xlabel=None)\n",
    "axes[1].tick_params(axis='x', labelrotation=90, labelbottom=True)\n",
    "_ = axes[1].set_title(\"North-America Logarithmic\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "573dc47e138064a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "- For every `native-region` except `North-America`, we have too little data\n",
    "  to differentiate by `race` and `sex`.  \n",
    "- For North America, we summarize `race=Asian-Pac-Islander`, `race=Amer-Indian-Eskimo`\n",
    "  and `race=Other` independent of `sex`, as we have too little data for these \n",
    "  subpopulations.\n",
    "  For `race=White` and `race=Black` we have sufficient data to split\n",
    "  these subpopulations further by `sex`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da4c1a114dadfecb"
  },
  {
   "cell_type": "code",
   "source": [
    "native_region_sex_race_mask = {}\n",
    "native_region_sex_race_values = {}  # for working with data_df\n",
    "\n",
    "# All regions except North-America\n",
    "for region_value in (\"South&Central-America&Pacific\", \"Asia\", \"Mexico\", \"Europe\"):\n",
    "    native_region_sex_race_mask[region_value] = {\n",
    "        \"native-country\": native_region_mask[region_value],\n",
    "        \"sex\": (torch.zeros(2), torch.ones(2)),\n",
    "        \"race\": (torch.zeros(5), torch.ones(5)),\n",
    "    }\n",
    "    native_region_sex_race_values[region_value] = (\n",
    "        (region_value,),\n",
    "        Adult.variables[\"sex\"],\n",
    "        Adult.variables[\"race\"],\n",
    "    )\n",
    "\n",
    "# North-America\n",
    "for race_value, j in ((\"White\", 0), (\"Black\", -1)):\n",
    "    for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "        key = f\"North-America-{sex_value}-{race_value}\"\n",
    "        native_region_sex_race_mask[key] = {\n",
    "            \"native-country\": native_region_mask[\"North-America\"],\n",
    "            \"sex\": (torch.eye(2)[i, :],) * 2,\n",
    "            \"race\": (torch.eye(5)[j, :],) * 2,\n",
    "        }\n",
    "        native_region_sex_race_values[key] = (\n",
    "            (\"North-America\",), (sex_value,), (race_value,)\n",
    "        )\n",
    "\n",
    "native_region_sex_race_mask[\"North-America-Remaining\"] = {\n",
    "    \"native-country\": native_region_mask[\"North-America\"],\n",
    "    \"sex\": (torch.zeros(2), torch.ones(2)),\n",
    "    \"race\": (torch.zeros(5), torch.tensor([0.0, 1.0, 1.0, 1.0, 0.0])),\n",
    "}\n",
    "native_region_sex_race_values[\"North-America-Remaining\"] = (\n",
    "    (\"North-America\",), \n",
    "    Adult.variables[\"sex\"], \n",
    "    (\"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\")\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eed070d0c044a31",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "resolve_to_group = {\n",
    "    f\"{region_value}-{sex_value}-{race_value}\": group_key\n",
    "    for group_key, (region_vals, sex_vals, race_vals) in native_region_sex_race_values.items()\n",
    "    for region_value in region_vals\n",
    "    for sex_value in sex_vals\n",
    "    for race_value in race_vals\n",
    "}\n",
    "\n",
    "def get_group(entry):\n",
    "    native_region_value = entry[\"native-region-names\"]\n",
    "    sex_value = entry[\"sex-names\"]\n",
    "    race_value = entry[\"race-names\"]\n",
    "    return resolve_to_group[\n",
    "        f\"{native_region_value}-{sex_value}-{race_value}\"\n",
    "    ]\n",
    "\n",
    "data_df[\"native-region-sex-race-group\"] = data_df.apply(get_group, axis=1)\n",
    "native_region_sex_race_subset_df = {\n",
    "    group_key: data_df[data_df[\"native-region-sex-race-group\"] == group_key]\n",
    "    for group_key in native_region_sex_race_mask\n",
    "}\n",
    "data_df[\"native-region-sex-race-group\"].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0b691a390ee7e54",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Age\n",
    "Next, we model `age`.\n",
    "\n",
    "We first have a look at the conditional probability distribution of `age`\n",
    "for the `native-region-sex-race` groups we have just created.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b114385465784bdc"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(native_region_sex_race_mask)\n",
    "num_rows = ceil(num_groups / 3)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(native_region_sex_race_subset_df.items()):\n",
    "    g = sns.histplot(\n",
    "        subset_df,\n",
    "        x=\"age\",\n",
    "        stat=\"percent\",\n",
    "        kde=True,\n",
    "        binwidth=1.0,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[i].set_title(group_key)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86fc7c444fc63c6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We fit Gaussian Mixture Models with varying numbers of components for all `native-region-sex-race`\n",
    "groups, except `North-America-Male-White`. \n",
    "For this group, we use a manually constructed single Gaussian distribution.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c641959e68860d0"
  },
  {
   "cell_type": "code",
   "source": [
    "num_components = {\n",
    "    \"South&Central-America&Pacific\": 4,\n",
    "    \"Asia\": 3,\n",
    "    \"Mexico\": 3,\n",
    "    \"Europe\": 2,\n",
    "    \"North-America-Female-White\": 3,\n",
    "    \"North-America-Female-Black\": 3,\n",
    "    \"North-America-Male-Black\": 3,\n",
    "    \"North-America-Remaining\": 2,\n",
    "}\n",
    "age_distributions = {\n",
    "    group_key: make_gaussian_mixture(\n",
    "        subset_df[\"age\"].to_numpy(),\n",
    "        var=\"age\",\n",
    "        n_components=num_components[group_key],\n",
    "        n_restarts=5,\n",
    "    )\n",
    "    for group_key, subset_df in native_region_sex_race_subset_df.items()\n",
    "    if group_key in num_components\n",
    "}\n",
    "\n",
    "age_min, age_max = adult_input_space.attribute_bounds(\"age\")\n",
    "north_am_male_white_loc = 35.0\n",
    "north_am_male_white_scale = 16.5\n",
    "age_distributions[\"North-America-Male-White\"] = AsInteger.wrap(truncnorm(\n",
    "    a=(age_min - north_am_male_white_loc) / north_am_male_white_scale,\n",
    "    b=(age_max - north_am_male_white_loc) / north_am_male_white_scale,\n",
    "    loc=north_am_male_white_loc,\n",
    "    scale=north_am_male_white_scale,\n",
    "))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b75ff1be0589e367",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(native_region_sex_race_mask)\n",
    "num_rows = ceil(num_groups / 3)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "n = 10000\n",
    "for i, (group_key, subset_df) in enumerate(native_region_sex_race_subset_df.items()):\n",
    "    age_data = age_distributions[group_key].sample(n, seed=get_seed(group_key))\n",
    "    generated_df = pd.DataFrame({\"age\": age_data, \"dataset\": \"generated\"})\n",
    "    df = pd.concat([generated_df, subset_df])\n",
    "    g = sns.histplot(\n",
    "        df,\n",
    "        x=\"age\",\n",
    "        hue=\"dataset\",\n",
    "        stat=\"percent\",\n",
    "        common_norm=False,\n",
    "        kde=True,\n",
    "        binwidth=1.0,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[i].set_title(group_key)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f8e6d2e03a5e025",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "age_node = bayes_net_factory.new_node(\"age\", replace=True)\n",
    "age_node.set_parents(native_country_node, sex_node, race_node)\n",
    "min_age, max_age = adult_input_space.attribute_bounds(\"age\")\n",
    "age_node.discrete_event_space(*[[age] for age in range(min_age, max_age+1)])\n",
    "\n",
    "for group_key, group_mask in native_region_sex_race_mask.items():\n",
    "    age_node.set_conditional_probability(group_mask, age_distributions[group_key])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d65668c6c292e12d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For making later nodes dependent on age, we introduce age groups.\n",
    "These age groups are based on https://www.census.gov/library/visualizations/interactive/exploring-age-groups-in-the-2020-census.html\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b8ef6a6739b26a4"
  },
  {
   "cell_type": "code",
   "source": [
    "age_group_mask = {\n",
    "    \"17-24\": ([17.0], [24.0]),\n",
    "    \"25-34\": ([25.0], [34.0]),\n",
    "    \"35-44\": ([35.0], [44.0]),\n",
    "    \"45-64\": ([45.0], [64.0]),\n",
    "    \"65-90\": ([65.0], [90.0]),\n",
    "}\n",
    "age_group_lookup = {\n",
    "    age: group_key\n",
    "    for group_key, (age_lb, age_ub) in age_group_mask.items()\n",
    "    for age in range(int(age_lb[0]), int(age_ub[0])+1)\n",
    "}\n",
    "data_df[\"age-group\"] = data_df[\"age\"].replace(age_group_lookup)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e3cbd3c66e9062",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fnlwgt\n",
    "The distribution of `fnlwgt` differs between `native-regions` and `races`,\n",
    "but does not differ significantly between `sexes`.\n",
    "This is apparent from the figure below.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "523578858ccf6d00"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display \n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 10.5))\n",
    "\n",
    "for i, var in enumerate((\"native-region-names\", \"sex-names\", \"race-names\", \"age-group\")):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"fnlwgt\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        kde=True,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4a124a4bf4ad5e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also when looking at `native-region` and `race` subpopulations, the distributions\n",
    "of `fnlwgt` do not differ much between `sexes`.\n",
    "Also for `age`, they do not differ much.\n",
    "\n",
    "Therefore, we model `fnlwgt` dependent on the `native-region-sex-race` groups,\n",
    "but do not differentiate different values of `sex` or `age`.\n",
    "In summary, this yields to differentiating the different `native-regions`\n",
    "and, additionally, differentiating `race=White`, `race=Black` and the remaining `race`\n",
    "values for `native-region=North-America`. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cff4826875f70c4e"
  },
  {
   "cell_type": "code",
   "source": [
    "native_region_race_mask = {\n",
    "    key: {var: val[var] for var in (\"native-country\", \"race\")}\n",
    "    for key, val in native_region_sex_race_mask.items()\n",
    "    if key not in (\n",
    "        \"North-America-Female-White\", \"North-America-Male-White\", \n",
    "        \"North-America-Female-Black\", \"North-America-Male-Black\"\n",
    "    )\n",
    "}\n",
    "native_region_race_values = {\n",
    "    key: (val[0], val[2]) \n",
    "    for key, val in native_region_sex_race_values.items() \n",
    "    if key in native_region_race_mask\n",
    "}\n",
    "\n",
    "for race_value, j in ((\"White\", 0), (\"Black\", -1)):\n",
    "    key = f\"North-America-{race_value}\"\n",
    "    native_region_race_mask[key] = {\n",
    "        \"native-country\": native_region_mask[\"North-America\"],\n",
    "        \"race\": (torch.eye(5)[j, :],) * 2,\n",
    "    }\n",
    "    native_region_race_values[key] = (\n",
    "        (\"North-America\",), (race_value,)\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "850ae35476efdb7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "native_region_race_subset_df = {\n",
    "    group_key: subset_df\n",
    "    for group_key, subset_df in native_region_sex_race_subset_df.items()\n",
    "    if group_key in native_region_race_mask\n",
    "}\n",
    "for race_value in (\"Black\", \"White\"):\n",
    "    native_region_race_subset_df[f\"North-America-{race_value}\"] = pd.concat(\n",
    "        [\n",
    "            native_region_sex_race_subset_df[f\"North-America-Female-{race_value}\"],\n",
    "            native_region_sex_race_subset_df[f\"North-America-Male-{race_value}\"]\n",
    "        ], axis=0\n",
    "    )\n",
    "\n",
    "overview = [\n",
    "    {\"Group\": group_key, \"Count\": len(subset_df)}\n",
    "    for group_key, subset_df in native_region_race_subset_df.items()\n",
    "]\n",
    "overview = pd.DataFrame(overview).sort_values(by=[\"Count\"], ascending=False)\n",
    "overview\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96cb2271cea3e324",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can actually build the conditional distributions.\n",
    "We use mixtures of `beta` and `truncnorm` distributions for all cases.\n",
    "For some cases, we manually construct `beta` distributions to fit the data.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe37c396df61c2f6"
  },
  {
   "cell_type": "code",
   "source": [
    "# Beta distributions produce values between 0.0 and 1.0. \n",
    "# We want to move 0.0 to fnlwgt_min and 1.0 to fnlwgt_max\n",
    "fnlwgt_min, fnlwgt_max = adult_input_space.attribute_bounds(\"fnlwgt\")\n",
    "\n",
    "fnlwgt_distributions = {}\n",
    "\n",
    "for group_key in (\"Asia\", \"Mexico\", \"Europe\", \"North-America-Remaining\", \"North-America-Black\"):\n",
    "    subset_df = native_region_race_subset_df[group_key]\n",
    "    a, b, _, _ = beta.fit(\n",
    "        subset_df[\"fnlwgt\"].to_numpy(),\n",
    "        floc=fnlwgt_min,\n",
    "        fscale=fnlwgt_max,\n",
    "    )\n",
    "    fnlwgt_distributions[group_key] = AsInteger.wrap(UnivariateContinuousDistribution(\n",
    "        beta(a, b, fnlwgt_min, fnlwgt_max),\n",
    "        bounds=(fnlwgt_min, fnlwgt_max)\n",
    "    ))\n",
    "\n",
    "fnlwgt_distributions[\"South&Central-America&Pacific\"] = AsInteger.wrap(UnivariateContinuousDistribution(\n",
    "    beta(\n",
    "        a=5.75,\n",
    "        b=35.0,\n",
    "        loc=fnlwgt_min,\n",
    "        scale=fnlwgt_max,\n",
    "    ),\n",
    "    bounds=(fnlwgt_min, fnlwgt_max)\n",
    "))\n",
    "\n",
    "fnlwgt_distributions[\"North-America-White\"] = AsInteger.wrap(UnivariateContinuousDistribution(\n",
    "    beta(\n",
    "        a=4.25,\n",
    "        b=30.0,\n",
    "        loc=fnlwgt_min,\n",
    "        scale=fnlwgt_max,\n",
    "    ),\n",
    "    bounds=(fnlwgt_min, fnlwgt_max)\n",
    "))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca4e4b91172a20a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(native_region_race_mask)\n",
    "num_rows = ceil(num_groups / 3)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "n = 10000\n",
    "for i, (group_key, subset_df) in enumerate(native_region_race_subset_df.items()):\n",
    "    fnlwgt_data = fnlwgt_distributions[group_key].sample(n, seed=get_seed(group_key))\n",
    "    generated_df = pd.DataFrame({\"fnlwgt\": fnlwgt_data, \"dataset\": \"generated\"})\n",
    "    df = pd.concat([generated_df, subset_df])\n",
    "    g = sns.histplot(\n",
    "        df,\n",
    "        x=\"fnlwgt\",\n",
    "        hue=\"dataset\",\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        kde=True,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[i].set_title(group_key)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfb9741221590abe",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fnlwgt_node = bayes_net_factory.new_node(\"fnlwgt\", replace=True)\n",
    "fnlwgt_node.set_parents(native_country_node, race_node)\n",
    "fnlwgt_node.continuous_event_space(*adult_input_space.attribute_bounds(\"fnlwgt\"))\n",
    "\n",
    "for group_key, group_mask in native_region_race_mask.items():\n",
    "    fnlwgt_node.set_conditional_probability(group_mask, fnlwgt_distributions[group_key])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef852bfe976dab7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### education\n",
    "We model `education` depending on the `race` and `age-group`.\n",
    "\n",
    "Looking at the distribution of `age-group`, there is one significant anomaly: people\n",
    "in the `age-group` `17-24` have a different distribution in `education`, as they are\n",
    "still in education.\n",
    "People in the `age-group` `25-34` also have, for example, fewer `Masters` degrees, but\n",
    "the differences are less pronounced.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "238a0201bdecc16f"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(4, 1, figsize=(13, 12))\n",
    "\n",
    "for i, var in enumerate((\"native-region-names\", \"sex-names\", \"race-names\", \"age-group\")):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"education-names\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    axes[i].tick_params(axis='x', labelrotation=90)\n",
    "    axes[i].set_title(var)\n",
    "    g.set(xlabel=None)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90b932505eddc466",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(native_region_sex_race_mask)\n",
    "num_rows = ceil(num_groups / 3)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(native_region_sex_race_subset_df.items()):\n",
    "    g = sns.histplot(\n",
    "        subset_df.sort_values(by=[\"education\"]),\n",
    "        x=\"education-names\",\n",
    "        stat=\"percent\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[i].tick_params(axis='x', labelrotation=90)\n",
    "    axes[i].set_title(group_key)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aafa45e0902da215",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "age_broad_mask = {\n",
    "    \"17-24\": ([17.0], [24.0]),\n",
    "    \"25-34\": ([25.0], [34.0]),\n",
    "    \">35\": ([35.0], [90.0]),\n",
    "}\n",
    "age_broad_lookup = {group: group if group in age_broad_mask else \">35\" for group in age_group_mask}\n",
    "data_df[\"age-broad\"] = data_df[\"age-group\"].replace(to_replace=age_broad_lookup)\n",
    "data_df.value_counts(subset=[\"age-broad\", \"race-names\"])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7461c45a73e080e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_rows = len(Adult.variables[\"race\"])\n",
    "fig, axes = plt.subplots(num_rows, len(age_broad_mask), figsize=(15, num_rows * 3.5))\n",
    "\n",
    "for i, race_value in enumerate(Adult.variables[\"race\"]):\n",
    "    for j, age_broad in enumerate(age_broad_mask):\n",
    "        subset_df = data_df[(data_df[\"race-names\"] == race_value) & (data_df[\"age-broad\"] == age_broad)]\n",
    "        g = sns.histplot(\n",
    "            subset_df.sort_values(by=[\"education\"]),\n",
    "            x=\"education-names\",\n",
    "            stat=\"percent\",\n",
    "            discrete=True,\n",
    "            shrink=0.8,\n",
    "            multiple=\"dodge\",\n",
    "            ax=axes[i][j],\n",
    "        )\n",
    "        g.set(xlabel=None)\n",
    "        axes[i][j].tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "for i, race_value in enumerate(Adult.variables[\"race\"]):\n",
    "    axes[i][0].set_ylabel(race_value)\n",
    "\n",
    "for j, age_broad in enumerate(age_broad_mask):\n",
    "    axes[0][j].set_title(age_broad)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecb9e5a7e92517ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We only have sufficient data for `race=White` and `race=Black` groups\n",
    "to further split by broad age groups (summarize all age groups order than 35).\n",
    "Therefore, the other values of `race` are not split by `age-broad`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d35cf709e0262d03"
  },
  {
   "cell_type": "code",
   "source": [
    "education_node = bayes_net_factory.new_node(\"education\", replace=True)\n",
    "education_node.set_parents(race_node, age_node)\n",
    "education_node.one_hot_event_space(len(Adult.variables[\"education\"]))\n",
    "\n",
    "for i, race_value in enumerate(Adult.variables[\"race\"]):\n",
    "    race_matches = data_df[\"race-names\"] == race_value\n",
    "    if race_value in (\"White\", \"Black\"):\n",
    "        for j, (age_broad, age_mask) in enumerate(age_broad_mask.items()):\n",
    "            age_broad_matches = data_df[\"age-broad\"] == age_broad\n",
    "            education_values = dataset.data[race_matches & age_broad_matches, :][:, col_idx[\"education\"]]\n",
    "            education_node.set_conditional_probability(\n",
    "                {\n",
    "                    \"race\": ([1.0 if k == i else 0.0 for k in range(len(Adult.variables[\"race\"]))],) * 2,\n",
    "                    \"age\": age_mask,\n",
    "                },\n",
    "                make_categorical(education_values)\n",
    "            )\n",
    "    else:\n",
    "        education_values = dataset.data[race_matches, :][:, col_idx[\"education\"]]\n",
    "        education_node.set_conditional_probability(\n",
    "            {\n",
    "                \"race\": ([1.0 if k == i else 0.0 for k in range(len(Adult.variables[\"race\"]))],) * 2,\n",
    "                \"age\": adult_input_space.attribute_bounds(\"age\"),\n",
    "            },\n",
    "            make_categorical(education_values)\n",
    "        )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee915b1257a9973f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For using `education` as a parent for further nodes, we summarize the following values:\n",
    "- `Preschool`, `1st-4th` - `12th` as `Primary-Secondary`\n",
    "- `HS-grad` (keep, >9000 instances)\n",
    "- `Assoc-acdm`, `Assoc-voc`, and `Some-College` as `Associate-Degree`\n",
    "- `Bachelors`, `Masters`, `Prof-school`, and `Doctorate` as `University-Degree`\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dc141171f11bcb0"
  },
  {
   "cell_type": "code",
   "source": [
    "data_df[\"education-group\"] = data_df[\"education-names\"]\n",
    "education_group_values = {\n",
    "    \"Primary-Secondary\": (\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\", \"9th\", \"10th\", \"11th\", \"12th\"),\n",
    "    \"HS-grad\": (\"HS-grad\",),\n",
    "    \"Associate-Degree\": (\"Assoc-acdm\", \"Assoc-voc\", \"Some-college\"),\n",
    "    \"University-Degree\": (\"Bachelors\", \"Masters\", \"Prof-school\", \"Doctorate\"),\n",
    "}\n",
    "education_group_lookup = {\n",
    "    value: group_key\n",
    "    for group_key, values in education_group_values.items()\n",
    "    for value in values\n",
    "}\n",
    "education_group_mask = {\n",
    "    group_key: (\n",
    "        torch.zeros(len(Adult.variables[\"education\"])),\n",
    "        torch.tensor(\n",
    "            [1.0 if val in values else 0.0 for val in Adult.variables[\"education\"]]\n",
    "        )\n",
    "    )\n",
    "    for group_key, values in education_group_values.items()\n",
    "}\n",
    "data_df[\"education-group\"].replace(education_group_lookup, inplace=True)\n",
    "data_df.value_counts(subset=[\"education-group\"])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdf96b73b1645e68",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### education-num\n",
    "As seen in the dataset section at the beginning of this notebook, \n",
    "`education-num` is entirely determined by `education`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff6ef6b39aa1ff0d"
  },
  {
   "cell_type": "code",
   "source": [
    "edu_num_node = bayes_net_factory.new_node(\"education-num\", replace=True)\n",
    "edu_num_node.set_parents(education_node)\n",
    "edu_num_node.continuous_event_space(*adult_input_space.attribute_bounds(\"education-num\"))\n",
    "\n",
    "edu_num_data = dataset_raw.data[:, col_raw_id[\"education-num\"]]\n",
    "edu_num_num_values = int(edu_num_data.max() + 1)\n",
    "\n",
    "for i, education_value in enumerate(Adult.variables[\"education\"]):\n",
    "    education_matches = dataset.data[:, col_idx[\"education\"][i]] == 1.0\n",
    "    edu_num_values = edu_num_data[education_matches]\n",
    "    edu_num_node.set_conditional_probability(\n",
    "        {education_node: ([1.0 if j == i else 0.0 for j in range(len(Adult.variables[\"education\"]))],) * 2},\n",
    "        make_categorical_flat(edu_num_values, edu_num_num_values)\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "726b6f5ce37d10b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### occupation, workclass, relationship, marital-status, hours-per-week\n",
    "The variables `occupation`, `workclass`, `relationship`, `marital-status`\n",
    "and `hours-per-week` represent life choices that can influence each other. \n",
    "To model this, we introduce a categorical latent variable that we infer from\n",
    "clustering using the KModes algorithm.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68f484001c6a7a4c"
  },
  {
   "cell_type": "code",
   "source": [
    "data_to_cluster = data_df[[\"occupation-names\", \"workclass-names\", \"relationship-names\", \"marital-status-names\", \"hours-per-week\"]]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45cc9ae21d88f661",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the clustering for all tested numbers of clusters takes about **three minutes**.\n",
    "If you skip the next two cells, the third next cell will run clustering only for\n",
    "the number of clusters we use in the following.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c375a021e4b00f2"
  },
  {
   "cell_type": "code",
   "source": [
    "num_clusters = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "clustering_cost = []\n",
    "clusterings = []\n",
    "for i, n_clusters in enumerate(tqdm(num_clusters)):\n",
    "    kmodes = KModes(n_clusters, n_init=3, random_state=1234)\n",
    "    kmodes.fit(data_to_cluster)\n",
    "    clustering_cost.append(kmodes.cost_)\n",
    "    clusterings.append(kmodes)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2996a88428d814a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "clustering_cost_df = pd.DataFrame({\"num_clusters\": num_clusters, \"cost\": clustering_cost})\n",
    "g = sns.lineplot(clustering_cost_df, x=\"num_clusters\", y=\"cost\", marker=\"o\")\n",
    "_ = g.set_xticks(num_clusters)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58da767bd139b095",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "From inspecting the above plot, we pick `n_clusters=8`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96dabfcc7e9bae17"
  },
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "    owrmh_clustering = clusterings[3]\n",
    "except NameError:\n",
    "    # Clustering not run (takes about three minutes)\n",
    "    kmodes = KModes(n_clusters=8, n_init=3, random_state=1234)\n",
    "    kmodes.fit(data_to_cluster)\n",
    "    owrmh_clustering = kmodes \n",
    "\n",
    "cluster_centroids = owrmh_clustering.cluster_centroids_\n",
    "cluster_assignment = owrmh_clustering.predict(data_to_cluster)\n",
    "# OWRMH => occupation, workclass, relationship, marital-status, hours-per-week\n",
    "data_df[\"OWRMH-cluster\"] = cluster_assignment\n",
    "\n",
    "_, cluster_sizes = np.unique(cluster_assignment, return_counts=True)\n",
    "df = pd.DataFrame(cluster_centroids)\n",
    "df[\"size\"] = cluster_sizes\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f745f5dd3f9afb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now investigate the distributions of `occupation`, `workclass`, `relationship`, \n",
    "`marital-status`, and `hours-per-week` across clusters.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13485f5db6ef1b11"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplot_mosaic(\n",
    "    [[\"o\", \"w\"], [\"r\", \"m\"], [\"h\", \"h\"]], \n",
    "    figsize=(15, 15)\n",
    ")\n",
    "vars = (\"occupation-names\", \"workclass-names\", \"relationship-names\", \"marital-status-names\", \"hours-per-week\")\n",
    "for var in vars:\n",
    "    ax = axes[var[0]]\n",
    "    ax.set_title(var)\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=var,\n",
    "        hue=\"OWRMH-cluster\",\n",
    "        common_norm=False,\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"percent\",\n",
    "        palette=sns.color_palette(),\n",
    "        legend=var in (\"workclass-names\", \"hours-per-week\"),\n",
    "        ax=ax,\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76bd87fffd82ae0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now consider how cluster membership depends on `native-region`, `sex`, `race`, \n",
    "`age-group` and `education-group`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36580ec49aa18665"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(5, 1, figsize=(13, 12))\n",
    "\n",
    "for i, var in enumerate((\"native-region-names\", \"sex-names\", \"race-names\", \"age-group\", \"education-group\")):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"OWRMH-cluster\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    axes[i].tick_params(axis='x', labelrotation=90)\n",
    "    axes[i].set_title(var)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "773076477fc7b9d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"OWRMH-cluster\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"native-region\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"age-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"education-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"native-region\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"age-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"education-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"native-region\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"education-group\"], target_var=\"OWRMH-cluster\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"native-region-sex-race-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\", \"native-region\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region-sex-race-group\", \"age-group\", \"education-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\", \"native-region\", \"age-group\", \"education-group\"], target_var=\"OWRMH-cluster\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11a27629b12af68d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The combination of `sex` and `age-group` is most associated with `OWRMH-cluster`.\n",
    "Further variables only marginally add to this combination.\n",
    "Therefore, we choose `sex` and `age-group` as the parents of the latent\n",
    "`OWRMH-cluster` node in our Bayesian network, that we introduce now.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6a655f4735bb9f7"
  },
  {
   "cell_type": "code",
   "source": [
    "owrmh_cluster_node = bayes_net_factory.new_node(\"OWRMH-cluster\", replace=True)\n",
    "owrmh_cluster_node.set_parents(sex_node, age_node)\n",
    "owrmh_cluster_node.discrete_event_space(*[[i] for i in range(owrmh_clustering.n_clusters)])\n",
    "\n",
    "for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "    for age_group, age_mask in age_group_mask.items():\n",
    "        subset_df = data_df[(data_df[\"sex-names\"] == sex_value) & (data_df[\"age-group\"] == age_group)]\n",
    "        owrmh_cluster_values = subset_df[\"OWRMH-cluster\"]\n",
    "        owrmh_cluster_values = torch.as_tensor(owrmh_cluster_values.to_numpy().astype(int))\n",
    "        owrmh_cluster_node.set_conditional_probability(\n",
    "            {\n",
    "                sex_node: ([1.0 if k == i else 0.0 for k in range(len(Adult.variables[\"sex\"]))],) * 2, \n",
    "                age_node: age_mask,\n",
    "            },\n",
    "            make_categorical_flat(owrmh_cluster_values, owrmh_clustering.n_clusters)\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f55d106b93950386",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### occupation\n",
    "We now come to modelling occupation based on the `OWRMH-cluster`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "719a694aa35312ce"
  },
  {
   "cell_type": "code",
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"occupation\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"native-region-sex-race-group\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\", \"native-region\", \"age-group\"], target_var=\"occupation\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"OWRMH-cluster\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\", \"OWRMH-cluster\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"OWRMH-cluster\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\", \"OWRMH-cluster\"], target_var=\"occupation\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\", \"native-region\", \"age-group\", \"education-group\", \"OWRMH-cluster\"], target_var=\"occupation\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6613bcb686eda54f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For most of the above combinations, we have insufficient data (less than 500 samples per combination).\n",
    "Only for `sex` x `OWRMH-cluster`, most combinations have sufficient data.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "497434f40be74098"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"OWRMH-cluster\",\n",
    "    y=\"sex-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True,\n",
    "    cmap=sns.color_palette(\"Spectral\", as_cmap=True),\n",
    "    cbar=True,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39c07680d1f2c19a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data_df.value_counts(subset=[\"sex-names\", \"OWRMH-cluster\"], ascending=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e463ef93448ab25",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to this, we do not differentiate by `sex` for the\n",
    "`OWRMH-clusters` `4`, `5`, `6`, and `7`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a860a7f435224a2"
  },
  {
   "cell_type": "code",
   "source": [
    "occupation_node = bayes_net_factory.new_node(\"occupation\", replace=True)\n",
    "occupation_node.set_parents(sex_node, owrmh_cluster_node)\n",
    "occupation_node.one_hot_event_space(len(Adult.variables[\"occupation\"]))\n",
    "\n",
    "for owrmh_cluster in range(owrmh_clustering.n_clusters):\n",
    "    owrmh_cluster_matches = data_df[\"OWRMH-cluster\"] == owrmh_cluster\n",
    "    if owrmh_cluster in (4, 5, 6, 7):\n",
    "        occupation_values = dataset.data[owrmh_cluster_matches, :][:, col_idx[\"occupation\"]]\n",
    "        occupation_node.set_conditional_probability(\n",
    "            {\n",
    "                sex_node: (torch.zeros(2), torch.ones(2)),\n",
    "                owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "            },\n",
    "            make_categorical(occupation_values)\n",
    "        )\n",
    "    else:\n",
    "        for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "            matches = (data_df[\"sex-names\"] == sex_value) & owrmh_cluster_matches \n",
    "            occupation_values = dataset.data[matches, :][:, col_idx[\"occupation\"]]\n",
    "            occupation_node.set_conditional_probability(\n",
    "                {\n",
    "                    sex_node: ([1.0 if k == i else 0.0 for k in range(len(Adult.variables[\"sex\"]))],) * 2,\n",
    "                    owrmh_cluster_node:([owrmh_cluster],) * 2,\n",
    "                },\n",
    "                make_categorical(occupation_values)\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0d66f291bae19dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### workclass\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54764a20d255eecd"
  },
  {
   "cell_type": "code",
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"occupation\"], target_var=\"workclass\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\", \"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\", \"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"occupation\", \"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"occupation\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"occupation\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\", \"occupation\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"occupation\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\", \"occupation\"], target_var=\"workclass\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"occupation\", \"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\", \"native-region\", \"age-group\", \"education-group\", \"occupation\", \"OWRMH-cluster\"], target_var=\"workclass\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be005ae74f48fa37",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The combinations of two variables that have a stronger association with `workclass`\n",
    "than `occupation` alone have many combinations with too little data.\n",
    "This is in particular because `occupation` has many values.\n",
    "We model `workclass` to be only dependent on `occupation`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef13737bcf56fdce"
  },
  {
   "cell_type": "code",
   "source": [
    "workclass_node = bayes_net_factory.new_node(\"workclass\", replace=True)\n",
    "workclass_node.set_parents(occupation_node)\n",
    "workclass_node.one_hot_event_space(len(Adult.variables[\"workclass\"]))\n",
    "\n",
    "for i, occupation_value in enumerate(Adult.variables[\"occupation\"]):\n",
    "    occupation_matches = dataset.data[:, col_idx[\"occupation\"][i]] == 1.0\n",
    "    workclass_values = dataset.data[occupation_matches][:, col_idx[\"workclass\"]]\n",
    "    workclass_node.set_conditional_probability(\n",
    "        {\n",
    "            occupation_node: ([1.0 if k == i else 0.0 for k in range(len(Adult.variables[\"occupation\"]))],) * 2,\n",
    "        },\n",
    "        make_categorical(workclass_values)\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccb83bd76babd709",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### relationship\n",
    "We model `relationship` before `marital-status`, as `relationship` is more predictive\n",
    "for `marital-status` than the other way around.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcaa9b6a59ffb7a3"
  },
  {
   "cell_type": "code",
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"relationship\")\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"age-group\", \"OWRMH-cluster\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\", \"native-region\", \"age-group\", \"education-num\", \"OWRMH-cluster\"], target_var=\"relationship\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1e4317eccdca521",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As for `occupation`, the combination of `sex` and `OWRMH-cluster` is strongly \n",
    "associated with `relationship`. Further variables add little to this combination.\n",
    "We follow the same scheme to model `relationship` as we did for `occupation`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac233d5fc56efd2b"
  },
  {
   "cell_type": "code",
   "source": [
    "relationship_node = bayes_net_factory.new_node(\"relationship\", replace=True)\n",
    "relationship_node.set_parents(sex_node, owrmh_cluster_node)\n",
    "relationship_node.one_hot_event_space(len(Adult.variables[\"relationship\"]))\n",
    "\n",
    "for owrmh_cluster in range(owrmh_clustering.n_clusters):\n",
    "    owrmh_cluster_matches = data_df[\"OWRMH-cluster\"] == owrmh_cluster\n",
    "    if owrmh_cluster in (4, 5, 6, 7):\n",
    "        relationship_values = dataset.data[owrmh_cluster_matches, :][:, col_idx[\"relationship\"]]\n",
    "        relationship_node.set_conditional_probability(\n",
    "            {\n",
    "                sex_node: (torch.zeros(2), torch.ones(2)),\n",
    "                owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "            },\n",
    "            make_categorical(relationship_values)\n",
    "        )\n",
    "    else:\n",
    "        for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "            matches = (data_df[\"sex-names\"] == sex_value) & owrmh_cluster_matches\n",
    "            relationship_values = dataset.data[matches, :][:, col_idx[\"relationship\"]]\n",
    "            relationship_node.set_conditional_probability(\n",
    "                {\n",
    "                    sex_node: ([1.0 if k == i else 0.0 for k in range(len(Adult.variables[\"sex\"]))],) * 2,\n",
    "                    owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "                },\n",
    "                make_categorical(relationship_values)\n",
    "            )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76d99f093e638d49",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### marital-status\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60b32c0b1353077f"
  },
  {
   "cell_type": "code",
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"relationship\"], target_var=\"marital-status\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\", \"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\", \"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"relationship\", \"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"relationship\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"relationship\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\", \"relationship\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"relationship\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\", \"relationship\"], target_var=\"marital-status\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"relationship\", \"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"relationship\", \"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\", \"native-region\", \"age-group\", \"education-group\", \"OWRMH-cluster\", \"relationship\"], target_var=\"marital-status\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bfa8b290669e8e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df, \n",
    "    x=\"OWRMH-cluster\", \n",
    "    y=\"relationship-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True, \n",
    "    cmap=sns.color_palette(\"Spectral\", as_cmap=True),\n",
    "    cbar=True, \n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc60e4b7ea356528",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combining `relationship` and `OWRMH-cluster` is highly predictive \n",
    "for `marital-status`.\n",
    "However, most combinations also have too little data.\n",
    "\n",
    "Instead, we model `marital-status` using the combination of `sex`\n",
    "and `OWRMH-cluster` that we also use for `occuation` and `relationship`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1c61994ed90f97a"
  },
  {
   "cell_type": "code",
   "source": [
    "marital_status_node = bayes_net_factory.new_node(\"marital-status\", replace=True)\n",
    "marital_status_node.set_parents(sex_node, owrmh_cluster_node)\n",
    "marital_status_node.one_hot_event_space(len(Adult.variables[\"marital-status\"]))\n",
    "\n",
    "for owrmh_cluster in range(owrmh_clustering.n_clusters):\n",
    "    owrmh_cluster_matches = data_df[\"OWRMH-cluster\"] == owrmh_cluster\n",
    "    if owrmh_cluster in (4, 5, 6, 7):\n",
    "        marital_status_values = dataset.data[owrmh_cluster_matches, :][:, col_idx[\"marital-status\"]]\n",
    "        marital_status_node.set_conditional_probability(\n",
    "            {\n",
    "                sex_node: (torch.zeros(2), torch.ones(2)),\n",
    "                owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "            },\n",
    "            make_categorical(marital_status_values)\n",
    "        )\n",
    "    else:\n",
    "        for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "            matches = (data_df[\"sex-names\"] == sex_value) & owrmh_cluster_matches\n",
    "            marital_status_values = dataset.data[matches, :][:, col_idx[\"marital-status\"]]\n",
    "            marital_status_node.set_conditional_probability(\n",
    "                {\n",
    "                    sex_node: ([1.0 if k == i else 0.0 for k in range(len(Adult.variables[\"sex\"]))],) * 2,\n",
    "                    owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "                },\n",
    "                make_categorical(marital_status_values)\n",
    "            )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36f3448966ae2e1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### hours-per-week\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c318dc6a8cc7bfa9"
  },
  {
   "cell_type": "code",
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"occupation\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"workclass\"], target_var=\"hours-per-week\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\", \"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\", \"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"occupation\", \"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"workclass\", \"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"occupation\", \"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\", \"native-region\", \"age-group\", \"education-group\", \"OWRMH-cluster\", \"occupation\", \"workclass\"], target_var=\"hours-per-week\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69cd09852e5f31e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15.0, 16.0))\n",
    "for i, var in enumerate((\"OWRMH-cluster\", \"age-group\", \"occupation-names\", \"workclass-names\")):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"hours-per-week\",\n",
    "        hue=var,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"percent\",\n",
    "        common_norm=False,\n",
    "        binwidth=1.0,\n",
    "        legend=True,\n",
    "        palette=sns.color_palette(),\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(ylabel=var, xlabel=None)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfeb13ff713517cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "One interesting observation we can make from the above plot is that people\n",
    "in the age groups `17-24` and `56-90` work shorter hours per week.\n",
    "However, `age-group` alone is less predictive than `OWRMH-cluster`\n",
    "and we have too little data to model the combination of both,\n",
    "in particular for the interesting `age-groups` `17-24` and `56-90`.\n",
    "\n",
    "We instead consider a combination of `OWRMH-cluster` and `occupation`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f53477a4c36c171"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df, \n",
    "    x=\"OWRMH-cluster\", \n",
    "    y=\"occupation-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True, \n",
    "    cmap=sns.color_palette(\"Spectral\", as_cmap=True),\n",
    "    cbar=True, \n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e34f8f348fd512c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We model `hours-per-week` using a combination of `occupation`\n",
    "and `OWRMH-cluster`.\n",
    "Since we have too little data to faithfully model using entire combination,\n",
    "we collapse all `occupation` x `OWRMH-cluster` combinations with less\n",
    "than 500 data points into a single group per `OWRMH-cluster`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a6378d42febf3dd"
  },
  {
   "cell_type": "code",
   "source": [
    "counts = data_df.value_counts(subset=[\"occupation-names\", \"OWRMH-cluster\"])\n",
    "occupation_owrmh_cluster_values = defaultdict(list)\n",
    "num_occupations = len(Adult.variables[\"occupation\"])\n",
    "for i, occupation_value in enumerate(Adult.variables[\"occupation\"]):\n",
    "    for owrmh_cluster in range(owrmh_clustering.n_clusters):\n",
    "        try:\n",
    "            count = counts[(occupation_value, owrmh_cluster)]\n",
    "        except KeyError:\n",
    "            count = 0\n",
    "        if count < 500:\n",
    "            occupation_owrmh_cluster_values[f\"Remaining-{owrmh_cluster}\"].append((occupation_value, owrmh_cluster))\n",
    "        else:\n",
    "            key = f\"{occupation_value}-{owrmh_cluster}\"\n",
    "            occupation_owrmh_cluster_values[key].append((occupation_value, owrmh_cluster))\n",
    "\n",
    "occupation_owrmh_cluster_mask = {}\n",
    "for group_key, values in occupation_owrmh_cluster_values.items():\n",
    "    occupation_values, owrmh_cluster = zip(*values)\n",
    "    owrmh_cluster = owrmh_cluster[0]  # cluster values are all equal\n",
    "    occupation_owrmh_cluster_mask[group_key] = {\n",
    "        \"occupation\": (\n",
    "            torch.zeros(len(Adult.variables[\"occupation\"])),\n",
    "            torch.tensor(\n",
    "                [1.0 if val in occupation_values else 0.0 for val in Adult.variables[\"occupation\"]]\n",
    "            )\n",
    "        ),\n",
    "        \"OWRMH-cluster\": torch.tensor([owrmh_cluster])\n",
    "    }\n",
    "\n",
    "occupation_owrmh_cluster_lookup = {\n",
    "    f\"{occupation}-{owrmh_cluster}\": group_key\n",
    "    for group_key, values in occupation_owrmh_cluster_values.items()\n",
    "    for occupation, owrmh_cluster in values\n",
    "}\n",
    "data_df[\"occupation-OWRMH-cluster-group\"] = data_df[\"occupation-names\"] + \"-\" + data_df[\"OWRMH-cluster\"].astype(str)\n",
    "data_df[\"occupation-OWRMH-cluster-group\"].replace(occupation_owrmh_cluster_lookup, inplace=True)\n",
    "data_df.value_counts(subset=[\"occupation-OWRMH-cluster-group\"], ascending=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ac5268cf7153852",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "uncertainty_coefficient(source_vars=[\"occupation\", \"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"occupation-OWRMH-cluster-group\"], target_var=\"hours-per-week\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2be9162f6ee8a09",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "hours_per_week_node = bayes_net_factory.new_node(\"hours-per-week\", replace=True)\n",
    "hours_per_week_node.set_parents(occupation_node, owrmh_cluster_node)\n",
    "min_hours_per_week, max_hours_per_week = adult_input_space.attribute_bounds(\"hours-per-week\")\n",
    "hours_per_week_node.discrete_event_space(*[[hours] for hours in range(min_hours_per_week, max_hours_per_week+1)])\n",
    "\n",
    "for group_key, group_mask in occupation_owrmh_cluster_mask.items():\n",
    "    subset_df = data_df[data_df[\"occupation-OWRMH-cluster-group\"] == group_key]\n",
    "    hours_per_week_values = subset_df[\"hours-per-week\"]\n",
    "    hours_per_week_values = torch.as_tensor(hours_per_week_values.to_numpy())\n",
    "    hours_per_week_node.set_conditional_probability(\n",
    "        group_mask, make_categorical_flat(hours_per_week_values, 100)\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "399f2c9a2479b67b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### capital-change\n",
    "In difference to the independent population model, we here model `capital-change`\n",
    "instead of `capital-loss` and `capital-gain` independently.\n",
    "Since these two variables are disjoint (the one is zero if the other is non-zero),\n",
    "it is simple to separate `capital-change` into the two using two `ReLUs` \n",
    "in an input transformation. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52b817ab860f3a4"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(11, 2, figsize=(15, 33))\n",
    "vars = (\n",
    "    \"sex-names\", \"race-names\", \"native-region-names\", \"native-region-sex-race-group\", \n",
    "    \"age-group\", \"education-group\", \"relationship-names\", \n",
    "    \"marital-status-names\", \"occupation-names\", \"workclass-names\"\n",
    ")\n",
    "for var, ax in zip(vars, axes):\n",
    "    for exclude_zero in (True, False):\n",
    "        df = data_df\n",
    "        if exclude_zero:\n",
    "            df = df[df[\"capital-change\"] != 0]\n",
    "        g = sns.histplot(\n",
    "            df.sort_values(by=[var]),\n",
    "            x=\"capital-change\",\n",
    "            hue=var,\n",
    "            common_norm=False,\n",
    "            stat=\"density\",\n",
    "            multiple=\"dodge\",\n",
    "            kde=True,\n",
    "            palette=sns.color_palette(),\n",
    "            ax=ax[int(exclude_zero)],\n",
    "        )\n",
    "        if not exclude_zero:\n",
    "            g.set(ylabel=var, title=\"All Data\")\n",
    "        else:\n",
    "            g.set(title=\"Without Zero\")\n",
    "        g.set(xlabel=None)\n",
    "\n",
    "for exclude_zero in (True, False):\n",
    "    df = data_df\n",
    "    if exclude_zero:\n",
    "        df = df[df[\"capital-change\"] != 0]\n",
    "    g = sns.histplot(\n",
    "        df,\n",
    "        x=\"capital-change\",\n",
    "        y=\"hours-per-week\",\n",
    "        cbar=exclude_zero,\n",
    "        ax=axes[-1][int(exclude_zero)],\n",
    "    )\n",
    "    if not exclude_zero:\n",
    "        g.set(ylabel=\"hours-per-week\", title=\"All Data\")\n",
    "    else:\n",
    "        g.set(title=\"Without Zero\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5fbc826d561e72c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The figure above shows that `capital-change` varies for many variables.\n",
    "The differences for `sex` might be explained by the differences in\n",
    "`relationship` for `sex`.\n",
    "The differences for `race` might be explained by the differences in\n",
    "`education-group` for `race`. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e5cdb7250319341"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(2, 1, figsize=(9, 6))\n",
    "for var, ax in zip((\"sex-names\", \"race-names\"), axes):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"relationship-names\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        shrink=.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=ax,\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c13317ec6079dbd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 12))\n",
    "for var, ax in zip((\"sex-names\", \"race-names\", \"age-group\"), axes):\n",
    "    g = sns.histplot(\n",
    "        data_df.sort_values(by=[\"education-group\", var]),\n",
    "        x=\"education-group\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        shrink=.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1f763b1480ab2eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We model `capital-change` using `relationship` and `education`.\n",
    "Since most combinations of `relationship` and `education` have too\n",
    "little data, we summarize values that have similar distributions\n",
    "of `capital-change`.\n",
    "\n",
    "For `relationship`, these are:\n",
    "- `Own-child` and `Other-relative` form one group.\n",
    "- All remaining values form the other group.\n",
    "\n",
    "For `education`, we use the groups created before.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "105be462eb92420c"
  },
  {
   "cell_type": "code",
   "source": [
    "data_df[\"relationship-group\"] = data_df[\"relationship-names\"]\n",
    "relationship_group_values = {\n",
    "    \"Own-child-Other-relative\": (\"Own-child\", \"Other-relative\"),\n",
    "    \"Remaining\": (\"Husband\", \"Wife\", \"Not-in-family\", \"Unmarried\"),\n",
    "}\n",
    "relationship_group_mask = {\n",
    "    group_key: (\n",
    "        torch.zeros(len(Adult.variables[\"relationship\"])),\n",
    "        torch.tensor(\n",
    "            [1.0 if val in values else 0.0 for val in Adult.variables[\"relationship\"]]\n",
    "        )\n",
    "    )\n",
    "    for group_key, values in relationship_group_values.items()\n",
    "}\n",
    "relationship_group_lookup = {\n",
    "    value: group_key\n",
    "    for group_key, values in relationship_group_values.items()\n",
    "    for value in values\n",
    "}\n",
    "data_df[\"relationship-group\"].replace(relationship_group_lookup, inplace=True)\n",
    "data_df.value_counts(subset=[\"relationship-group\"])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42977bb79c50de86",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data_df.value_counts(subset=[\"relationship-group\", \"education-group\"])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81433378e8728662",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For `Own-child-Other-relative`, we further summarize `University-Degree` \n",
    "and `Associate-Degree`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d27e2cc817dc75ff"
  },
  {
   "cell_type": "code",
   "source": [
    "data_df[\"relationship-education-group\"] = data_df[\"relationship-group\"] + \"-\" + data_df[\"education-group\"]\n",
    "data_df[\"relationship-education-group\"].replace(\n",
    "    {\n",
    "        f\"Own-child-Other-relative-{edu_val}\": \"Own-child-Other-relative-Higher-Degree\" \n",
    "        for edu_val in (\"University-Degree\", \"Associate-Degree\")\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "counts = data_df.value_counts(subset=\"relationship-education-group\")\n",
    "\n",
    "relationship_education_group_mask = {}\n",
    "for group_key in counts.index:\n",
    "    masks = {}\n",
    "    relationship_education_group_mask[group_key] = masks  # dicts are objects\n",
    "    if group_key.startswith(\"Remaining\"):\n",
    "        group_key = group_key[len(\"Remaining-\"):]\n",
    "        masks[\"relationship\"] = relationship_group_mask[\"Remaining\"]\n",
    "    else:\n",
    "        group_key = group_key[len(\"Own-child-Other-relative-\"):]\n",
    "        masks[\"relationship\"] = relationship_group_mask[\"Own-child-Other-relative\"]\n",
    "    if group_key == \"Higher-Degree\":\n",
    "        masks[\"education\"] = (\n",
    "            torch.zeros(len(Adult.variables[\"education\"])),\n",
    "            education_group_mask[\"Associate-Degree\"][1] + education_group_mask[\"University-Degree\"][1]\n",
    "        )\n",
    "    else:\n",
    "        masks[\"education\"] = education_group_mask[group_key]\n",
    "counts\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5a4536801450326",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similarly as for the independent population model, we fit a mixture of a \n",
    "categorical distribution for outliers and a Gaussian Mixture \n",
    "for the remaining data to `capital-change`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b713a3c03838b917"
  },
  {
   "cell_type": "code",
   "source": [
    "capital_change_data = data_df[\"capital-change\"]\n",
    "outliers = [0.0, capital_change_data.max()]\n",
    "is_outlier = capital_change_data.isin(outliers)\n",
    "capital_change_min = -adult_input_space.attribute_bounds(\"capital-loss\")[1]\n",
    "capital_change_max = adult_input_space.attribute_bounds(\"capital-gain\")[1] \n",
    "\n",
    "def make_capital_change_mixture(relationship_education_group, n_components):\n",
    "    matches_group = data_df[\"relationship-education-group\"] == relationship_education_group\n",
    "    outlier_data = capital_change_data[is_outlier & matches_group]\n",
    "    regular_data = capital_change_data[~is_outlier & matches_group]\n",
    "    outlier_frequency = outlier_data.astype(int).value_counts(normalize=True)\n",
    "    outliers_distribution = Categorical(\n",
    "        outlier_frequency.tolist(), outlier_frequency.index.tolist()\n",
    "    )\n",
    "\n",
    "    regular_data = regular_data.to_numpy().reshape(-1, 1)\n",
    "    mixture_model = make_gaussian_mixture(\n",
    "        regular_data, n_components, n_restarts=3, \n",
    "        var_min=capital_change_min, var_max=capital_change_max,\n",
    "    )\n",
    "    mixture_model = mixture_model.continuous_distribution\n",
    "\n",
    "    # add the outlier distribution to the mixture model\n",
    "    n_group = sum(matches_group)\n",
    "    components = list(mixture_model.distributions) + [outliers_distribution]\n",
    "    weights = list(mixture_model.weights * len(regular_data)/n_group)\n",
    "    weights += [len(outlier_data)/n_group]\n",
    "    return AsInteger(MixtureModel(weights, components))\n",
    "\n",
    "num_components = {\n",
    "    \"Remaining-Primary-Secondary\": 4,\n",
    "    \"Remaining-HS-grad\": 3,\n",
    "    \"Remaining-Associate-Degree\": 4,\n",
    "    \"Remaining-University-Degree\": 2,\n",
    "    \"Own-child-Other-relative-Primary-Secondary\": 2,\n",
    "    \"Own-child-Other-relative-HS-grad\": 2,\n",
    "    \"Own-child-Other-relative-Higher-Degree\": 2,\n",
    "}\n",
    "capital_change_distributions = {\n",
    "    group_key: make_capital_change_mixture(\n",
    "        group_key, n_components\n",
    "    )\n",
    "    for group_key, n_components in num_components.items()\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5aceee9465b0ee7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(relationship_education_group_mask)\n",
    "fig, axes = plt.subplots(num_groups, 2, figsize=(15, num_groups * 3.5))\n",
    "\n",
    "n = 10000\n",
    "for i, group_key in enumerate(relationship_education_group_mask):\n",
    "    capital_change_data = capital_change_distributions[group_key].sample(n, seed=get_seed(group_key))\n",
    "    generated_df = pd.DataFrame({\"capital-change\": capital_change_data, \"dataset\": \"generated\"})\n",
    "    subset_df = data_df[data_df[\"relationship-education-group\"] == group_key]\n",
    "    df = pd.concat([generated_df, subset_df])\n",
    "    for exclude_zero in (True, False):\n",
    "        df_ = df\n",
    "        if exclude_zero:\n",
    "            df_ = df[df[\"capital-change\"] != 0]\n",
    "        g = sns.histplot(\n",
    "            df_,\n",
    "            x=\"capital-change\",\n",
    "            hue=\"dataset\",\n",
    "            common_norm=False,\n",
    "            stat=\"density\",\n",
    "            kde=True,\n",
    "            bins=150,\n",
    "            ax=axes[i][int(exclude_zero)],\n",
    "        )\n",
    "        if not exclude_zero:\n",
    "            g.set(ylabel=group_key, title=\"All Data\")\n",
    "        else:\n",
    "            g.set(title=\"Without Zero\")\n",
    "        g.set(xlabel=None)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc59733ece140014",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "capital_change_node = bayes_net_factory.new_node(\"capital-change\", replace=True)\n",
    "capital_change_node.set_parents(education_node, relationship_node)\n",
    "capital_change_node.continuous_event_space(capital_change_min, capital_change_max)\n",
    "\n",
    "for group_key, group_mask in relationship_education_group_mask.items():\n",
    "    capital_change_node.set_conditional_probability(group_mask, capital_change_distributions[group_key])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67701841a25b038a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the `BayesianNetwork` from the `BayesianNetworkFactory`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ca00d98cefe0da"
  },
  {
   "cell_type": "code",
   "source": [
    "# allows testing the network before all nodes were added\n",
    "modelled_vars = [\n",
    "    var \n",
    "    for var in adult_input_space.attribute_names \n",
    "    if var in bayes_net_factory.nodes\n",
    "] + [\"capital-change\", \"OWRMH-cluster\"]\n",
    "bayes_net_factory.reorder_nodes(modelled_vars)\n",
    "bayes_net = bayes_net_factory.create()\n",
    "modelled_vars\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c0503e0da28b8b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "var_types = {\n",
    "    var: adult_input_space.attribute_type(var)\n",
    "    for var in modelled_vars\n",
    "    if var in Adult.variables\n",
    "}\n",
    "var_types |= {\n",
    "    \"OWRMH-cluster\": TabularInputSpace.AttributeType.INTEGER,\n",
    "    \"capital-change\": TabularInputSpace.AttributeType.INTEGER\n",
    "}\n",
    "integer_ranges = {\n",
    "    var: adult_input_space.attribute_bounds(var)\n",
    "    for var in modelled_vars\n",
    "    if var in Adult.variables and Adult.variables[var] is None\n",
    "}\n",
    "integer_ranges |= {\n",
    "    \"OWRMH-cluster\": (0, owrmh_clustering.n_clusters),\n",
    "    \"capital-change\": (capital_change_min, capital_change_max),\n",
    "}\n",
    "categorical_values = {\n",
    "    var: adult_input_space.attribute_values(var) \n",
    "    for var in modelled_vars \n",
    "    if var in Adult.variables and Adult.variables[var] is not None\n",
    "}\n",
    "bayes_net_input_space = TabularInputSpace(\n",
    "    modelled_vars,\n",
    "    data_types=var_types,\n",
    "    continuous_ranges={},\n",
    "    integer_ranges=integer_ranges,\n",
    "    categorical_values=categorical_values,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea869af9e7f6d771",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize the Population Model\n",
    "### Marginal Distributions\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "847eb62a9951e390"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "n = 10000\n",
    "generated_data = bayes_net.sample(n, seed=get_seed(\"bayes net\"))\n",
    "generated_raw = {}\n",
    "subspace_layout = bayes_net_input_space.encoding_layout\n",
    "for var in modelled_vars:\n",
    "    cols = subspace_layout[var]\n",
    "    if isinstance(cols, int):\n",
    "        generated_raw[var] = generated_data[:, cols]\n",
    "    else:\n",
    "        values_one_hot = generated_data[:, list(cols.values())]\n",
    "        values = np.argmax(values_one_hot, axis=1)\n",
    "        generated_raw[var] = values\n",
    "\n",
    "generated_raw[\"capital-gain\"] = torch.clamp(generated_raw[\"capital-change\"], min=0)\n",
    "generated_raw[\"capital-loss\"] = -torch.clamp(generated_raw[\"capital-change\"], max=0)\n",
    "modelled_vars += [\"capital-gain\", \"capital-loss\"]\n",
    "\n",
    "generated_df_ = pd.DataFrame(generated_raw)\n",
    "generated_df = pd.DataFrame(generated_raw)\n",
    "\n",
    "# Convert categorical variables from integer ids to string names\n",
    "for var in modelled_vars:\n",
    "    if var not in Adult.variables:\n",
    "        continue\n",
    "    values = Adult.variables[var]\n",
    "    if values is not None:\n",
    "        generated_df[f\"{var}-names\"] = data_df[var]\n",
    "        for i, value in enumerate(values):\n",
    "            generated_df[f\"{var}-names\"].replace(i, value, inplace=True)\n",
    "\n",
    "generated_df[\"dataset\"] = \"generated\"\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "generated_df\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a987d845b9e27677",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplot_mosaic(\n",
    "    [\n",
    "        [\"age\", \"workclass\", \"fnlwgt\", \"education\"], \n",
    "        [\"education-num\", \"marital-status\", \"occupation\", \"relationship\"],\n",
    "        [\"race\", \"sex\", \"native-country\", \"native-country\"],\n",
    "        [\"hours-per-week\"] * 4,\n",
    "        [\"capital-gain-full\"] * 2 + [\"capital-gain-non-zero\"] * 2,\n",
    "        [\"capital-loss-full\"] * 2 + [\"capital-loss-non-zero\"] * 2,\n",
    "    ], \n",
    "    figsize=(15, 30)\n",
    ")\n",
    "for var in adult_input_space.attribute_names:\n",
    "    if var in (\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"native-country\",\n",
    "    ): # categorical variables\n",
    "        kwargs = {}\n",
    "        if var == \"native-country\":\n",
    "            kwargs[\"log_scale\"] = (False, True)\n",
    "        var_show = var\n",
    "        if var != \"education-num\":\n",
    "            var_show = f\"{var}-names\"\n",
    "        g = sns.histplot(\n",
    "            df,\n",
    "            x=var_show,\n",
    "            hue=\"dataset\",\n",
    "            discrete=True,\n",
    "            shrink=0.8,\n",
    "            multiple=\"dodge\",\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            legend=False,\n",
    "            ax=axes[var],\n",
    "            **kwargs,\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "        axes[var].tick_params(axis='x', labelrotation=90)\n",
    "    elif var.startswith(\"capital\"):\n",
    "        for exclude_zero in (True, False):\n",
    "            if exclude_zero:\n",
    "                df_ = df[df[\"capital-change\"] != 0]\n",
    "                ax_key = f\"{var}-non-zero\"\n",
    "            else:\n",
    "                df_ = df\n",
    "                ax_key = f\"{var}-full\"\n",
    "            g = sns.histplot(\n",
    "                df_,\n",
    "                x=var,\n",
    "                hue=\"dataset\",\n",
    "                common_norm=False,\n",
    "                stat=\"density\",\n",
    "                kde=True,\n",
    "                bins=150,\n",
    "                ax=axes[ax_key],\n",
    "            )\n",
    "            if not exclude_zero:\n",
    "                g.set(title=f\"{var} - All Data\")\n",
    "            else:\n",
    "                g.set(title=f\"{var} - Without Zero\")\n",
    "            g.set(xlabel=None)\n",
    "    else:\n",
    "        kwargs = {\"legend\": False}\n",
    "        if var in (\"age\", \"hours-per-week\"):\n",
    "            kwargs[\"binwidth\"] = 1.0\n",
    "            kwargs[\"legend\"] = True\n",
    "        if var == (\"hours-per-week\"):\n",
    "            kwargs[\"multiple\"] = \"dodge\"\n",
    "        if var in (\"age\", \"fnlwgt\"):\n",
    "            kwargs[\"kde\"] = True\n",
    "        g = sns.histplot(\n",
    "            df,\n",
    "            x=var,\n",
    "            hue=\"dataset\",\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            ax=axes[var],\n",
    "            **kwargs,\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "plt.subplots_adjust(hspace=1.0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd20fcff2a3ed8ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare Correlation Matrices\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6306a8b3c3af04a7"
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "generated_df_ = generated_df[[var for var in Adult.variables if var in modelled_vars]]\n",
    "pop_model_corrcoef = np.corrcoef(generated_df_.to_numpy().T)\n",
    "data_corrcoef = np.corrcoef(dataset_raw.data.T.numpy())\n",
    "diff = pop_model_corrcoef - data_corrcoef\n",
    "for corrcoef, ax in zip((pop_model_corrcoef, data_corrcoef, diff), axes):\n",
    "    _ = sns.heatmap(\n",
    "        corrcoef,\n",
    "        vmin=-1.0,\n",
    "        vmax=1.0,\n",
    "        square=True,\n",
    "        cmap=\"RdBu\",\n",
    "        xticklabels=dataset_raw.columns,\n",
    "        yticklabels=dataset_raw.columns,\n",
    "        ax=ax,\n",
    "    )\n",
    "_ = axes[0].set_title(\"Population Model\")\n",
    "_ = axes[1].set_title(\"Training Data\")\n",
    "_ = axes[2].set_title(\"Difference\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f9d9811931c0bbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export Population Model\n",
    "As for the independent population model, we still need to normalize the continuous\n",
    "variables.\n",
    "Additionally, we need to split `capital-change` into `capital-gain`\n",
    "and `capital-loss`.\n",
    "The latent variable `OWRMH-cluster` that we introduced is simply thrown away.\n",
    "\n",
    "For splitting `capital-change`, we need a ReLU layer. \n",
    "Overall, our input transformation consists of a linear layer, a ReLU layer,\n",
    "and another linear layer.\n",
    "The first linear layer duplicates `capital-change` (and flips the sign of the second copy)\n",
    "and throws away `OWRMH-cluster`.\n",
    "The ReLU layer creates `capital-gain` and `capital-loss` by cutting of negative\n",
    "values.\n",
    "Lucky all other variables have non-negative values, so that applying ReLU is harmless.\n",
    "The final linear layer applies z-score normalization.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "855fd84c0ce05786"
  },
  {
   "cell_type": "code",
   "source": [
    "capital_change_index = modelled_vars.index(\"capital-change\")\n",
    "weight = torch.zeros(adult_input_space.input_shape + bayes_net_input_space.input_shape)\n",
    "wi = wj = 0\n",
    "for i, var in enumerate(adult_input_space.attribute_names):\n",
    "    if var == \"capital-gain\":\n",
    "        weight[wi, capital_change_index] = 1.0\n",
    "        wi += 1\n",
    "        # don't increment wj as capital-gain does not \n",
    "        # appear in the bayes_net_input_space\n",
    "    elif var == \"capital-loss\":\n",
    "        weight[wi, capital_change_index] = -1.0\n",
    "        wi += 1\n",
    "    else:\n",
    "        match adult_input_space.attribute_type(var):\n",
    "            case TabularInputSpace.AttributeType.CATEGORICAL:\n",
    "                for _ in range(len(ind_input_space.attribute_values(var))):\n",
    "                    weight[wi, wj] = 1.0\n",
    "                    wi += 1\n",
    "                    wj += 1\n",
    "            case _:\n",
    "                weight[wi, wj] = 1.0\n",
    "                wi += 1\n",
    "                wj += 1\n",
    "copy_vars = nn.Linear(weight.size(1), weight.size(0), bias=False)\n",
    "with torch.no_grad():\n",
    "    copy_vars.weight = nn.Parameter(weight, requires_grad=False)\n",
    "# for normalization, we can reuse the input transform \n",
    "# of the independent population model\n",
    "bayes_net_transform = nn.Sequential(\n",
    "    copy_vars, nn.ReLU(), ind_transform\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21ce2eeb65f328cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(\n",
    "    (bayes_net, bayes_net_input_space, bayes_net_transform),\n",
    "    \"../../resources/adult/bayesian_network_population_model.pyt\",\n",
    "    pickle_module=dill,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ffe6fd4b22fa8b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "182a51b64ed4af76",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
